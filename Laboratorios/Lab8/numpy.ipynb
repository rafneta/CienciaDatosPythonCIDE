{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/rafneta/CienciaDatosPythonCIDE/master/imagenes/banner.png)\n",
    "\n",
    "\n",
    "# NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Página principal de NumPy](https://numpy.org/)\n",
    "- [Documentación](https://numpy.org/doc/stable/)\n",
    "\n",
    "\n",
    "![Image](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-020-2649-2/MediaObjects/41586_2020_2649_Fig2_HTML.png?as=webp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLOW_THREADS',\n",
       " 'AxisError',\n",
       " 'BUFSIZE',\n",
       " 'CLIP',\n",
       " 'ComplexWarning',\n",
       " 'DataSource',\n",
       " 'ERR_CALL',\n",
       " 'ERR_DEFAULT',\n",
       " 'ERR_IGNORE',\n",
       " 'ERR_LOG',\n",
       " 'ERR_PRINT',\n",
       " 'ERR_RAISE',\n",
       " 'ERR_WARN',\n",
       " 'FLOATING_POINT_SUPPORT',\n",
       " 'FPE_DIVIDEBYZERO',\n",
       " 'FPE_INVALID',\n",
       " 'FPE_OVERFLOW',\n",
       " 'FPE_UNDERFLOW',\n",
       " 'False_',\n",
       " 'Inf',\n",
       " 'Infinity',\n",
       " 'MAXDIMS',\n",
       " 'MAY_SHARE_BOUNDS',\n",
       " 'MAY_SHARE_EXACT',\n",
       " 'MachAr',\n",
       " 'ModuleDeprecationWarning',\n",
       " 'NAN',\n",
       " 'NINF',\n",
       " 'NZERO',\n",
       " 'NaN',\n",
       " 'PINF',\n",
       " 'PZERO',\n",
       " 'RAISE',\n",
       " 'RankWarning',\n",
       " 'SHIFT_DIVIDEBYZERO',\n",
       " 'SHIFT_INVALID',\n",
       " 'SHIFT_OVERFLOW',\n",
       " 'SHIFT_UNDERFLOW',\n",
       " 'ScalarType',\n",
       " 'Tester',\n",
       " 'TooHardError',\n",
       " 'True_',\n",
       " 'UFUNC_BUFSIZE_DEFAULT',\n",
       " 'UFUNC_PYVALS_NAME',\n",
       " 'VisibleDeprecationWarning',\n",
       " 'WRAP',\n",
       " '_NoValue',\n",
       " '_UFUNC_API',\n",
       " '__NUMPY_SETUP__',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__git_revision__',\n",
       " '__loader__',\n",
       " '__mkl_version__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_add_newdoc_ufunc',\n",
       " '_distributor_init',\n",
       " '_globals',\n",
       " '_mat',\n",
       " '_pytesttester',\n",
       " 'abs',\n",
       " 'absolute',\n",
       " 'add',\n",
       " 'add_docstring',\n",
       " 'add_newdoc',\n",
       " 'add_newdoc_ufunc',\n",
       " 'alen',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alltrue',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply_along_axis',\n",
       " 'apply_over_axes',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccosh',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctanh',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'argwhere',\n",
       " 'around',\n",
       " 'array',\n",
       " 'array2string',\n",
       " 'array_equal',\n",
       " 'array_equiv',\n",
       " 'array_repr',\n",
       " 'array_split',\n",
       " 'array_str',\n",
       " 'asanyarray',\n",
       " 'asarray',\n",
       " 'asarray_chkfinite',\n",
       " 'ascontiguousarray',\n",
       " 'asfarray',\n",
       " 'asfortranarray',\n",
       " 'asmatrix',\n",
       " 'asscalar',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'average',\n",
       " 'bartlett',\n",
       " 'base_repr',\n",
       " 'binary_repr',\n",
       " 'bincount',\n",
       " 'bitwise_and',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_xor',\n",
       " 'blackman',\n",
       " 'block',\n",
       " 'bmat',\n",
       " 'bool',\n",
       " 'bool8',\n",
       " 'bool_',\n",
       " 'broadcast',\n",
       " 'broadcast_arrays',\n",
       " 'broadcast_to',\n",
       " 'busday_count',\n",
       " 'busday_offset',\n",
       " 'busdaycalendar',\n",
       " 'byte',\n",
       " 'byte_bounds',\n",
       " 'bytes0',\n",
       " 'bytes_',\n",
       " 'c_',\n",
       " 'can_cast',\n",
       " 'cast',\n",
       " 'cbrt',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'cfloat',\n",
       " 'char',\n",
       " 'character',\n",
       " 'chararray',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'clongdouble',\n",
       " 'clongfloat',\n",
       " 'column_stack',\n",
       " 'common_type',\n",
       " 'compare_chararrays',\n",
       " 'compat',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex256',\n",
       " 'complex64',\n",
       " 'complex_',\n",
       " 'complexfloating',\n",
       " 'compress',\n",
       " 'concatenate',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'convolve',\n",
       " 'copy',\n",
       " 'copysign',\n",
       " 'copyto',\n",
       " 'core',\n",
       " 'corrcoef',\n",
       " 'correlate',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cross',\n",
       " 'csingle',\n",
       " 'ctypeslib',\n",
       " 'cumprod',\n",
       " 'cumproduct',\n",
       " 'cumsum',\n",
       " 'datetime64',\n",
       " 'datetime_as_string',\n",
       " 'datetime_data',\n",
       " 'deg2rad',\n",
       " 'degrees',\n",
       " 'delete',\n",
       " 'deprecate',\n",
       " 'deprecate_with_doc',\n",
       " 'diag',\n",
       " 'diag_indices',\n",
       " 'diag_indices_from',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diff',\n",
       " 'digitize',\n",
       " 'disp',\n",
       " 'divide',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dsplit',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'e',\n",
       " 'ediff1d',\n",
       " 'einsum',\n",
       " 'einsum_path',\n",
       " 'emath',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'equal',\n",
       " 'error_message',\n",
       " 'errstate',\n",
       " 'euler_gamma',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'expand_dims',\n",
       " 'expm1',\n",
       " 'extract',\n",
       " 'eye',\n",
       " 'fabs',\n",
       " 'fastCopyAndTranspose',\n",
       " 'fft',\n",
       " 'fill_diagonal',\n",
       " 'find_common_type',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'flatiter',\n",
       " 'flatnonzero',\n",
       " 'flexible',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float128',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_',\n",
       " 'float_power',\n",
       " 'floating',\n",
       " 'floor',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'format_float_positional',\n",
       " 'format_float_scientific',\n",
       " 'format_parser',\n",
       " 'frexp',\n",
       " 'frombuffer',\n",
       " 'fromfile',\n",
       " 'fromfunction',\n",
       " 'fromiter',\n",
       " 'frompyfunc',\n",
       " 'fromregex',\n",
       " 'fromstring',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'fv',\n",
       " 'gcd',\n",
       " 'generic',\n",
       " 'genfromtxt',\n",
       " 'geomspace',\n",
       " 'get_array_wrap',\n",
       " 'get_include',\n",
       " 'get_printoptions',\n",
       " 'getbufsize',\n",
       " 'geterr',\n",
       " 'geterrcall',\n",
       " 'geterrobj',\n",
       " 'gradient',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'half',\n",
       " 'hamming',\n",
       " 'hanning',\n",
       " 'heaviside',\n",
       " 'histogram',\n",
       " 'histogram2d',\n",
       " 'histogram_bin_edges',\n",
       " 'histogramdd',\n",
       " 'hsplit',\n",
       " 'hstack',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'identity',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'in1d',\n",
       " 'index_exp',\n",
       " 'indices',\n",
       " 'inexact',\n",
       " 'inf',\n",
       " 'info',\n",
       " 'infty',\n",
       " 'inner',\n",
       " 'insert',\n",
       " 'int',\n",
       " 'int0',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_',\n",
       " 'intc',\n",
       " 'integer',\n",
       " 'interp',\n",
       " 'intersect1d',\n",
       " 'intp',\n",
       " 'invert',\n",
       " 'ipmt',\n",
       " 'irr',\n",
       " 'is_busday',\n",
       " 'isclose',\n",
       " 'iscomplex',\n",
       " 'iscomplexobj',\n",
       " 'isfinite',\n",
       " 'isfortran',\n",
       " 'isin',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isnat',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'isrealobj',\n",
       " 'isscalar',\n",
       " 'issctype',\n",
       " 'issubclass_',\n",
       " 'issubdtype',\n",
       " 'issubsctype',\n",
       " 'iterable',\n",
       " 'ix_',\n",
       " 'kaiser',\n",
       " 'kron',\n",
       " 'lcm',\n",
       " 'ldexp',\n",
       " 'left_shift',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lexsort',\n",
       " 'lib',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'little_endian',\n",
       " 'load',\n",
       " 'loads',\n",
       " 'loadtxt',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log1p',\n",
       " 'log2',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logspace',\n",
       " 'long',\n",
       " 'longcomplex',\n",
       " 'longdouble',\n",
       " 'longfloat',\n",
       " 'longlong',\n",
       " 'lookfor',\n",
       " 'ma',\n",
       " 'mafromtxt',\n",
       " 'mask_indices',\n",
       " 'mat',\n",
       " 'math',\n",
       " 'matmul',\n",
       " 'matrix',\n",
       " 'matrixlib',\n",
       " 'max',\n",
       " 'maximum',\n",
       " 'maximum_sctype',\n",
       " 'may_share_memory',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memmap',\n",
       " 'meshgrid',\n",
       " 'mgrid',\n",
       " 'min',\n",
       " 'min_scalar_type',\n",
       " 'minimum',\n",
       " 'mintypecode',\n",
       " 'mirr',\n",
       " 'mkl',\n",
       " 'mod',\n",
       " 'modf',\n",
       " 'moveaxis',\n",
       " 'msort',\n",
       " 'multiply',\n",
       " 'nan',\n",
       " 'nan_to_num',\n",
       " 'nanargmax',\n",
       " 'nanargmin',\n",
       " 'nancumprod',\n",
       " 'nancumsum',\n",
       " 'nanmax',\n",
       " 'nanmean',\n",
       " 'nanmedian',\n",
       " 'nanmin',\n",
       " 'nanpercentile',\n",
       " 'nanprod',\n",
       " 'nanquantile',\n",
       " 'nanstd',\n",
       " 'nansum',\n",
       " 'nanvar',\n",
       " 'nbytes',\n",
       " 'ndarray',\n",
       " 'ndenumerate',\n",
       " 'ndfromtxt',\n",
       " 'ndim',\n",
       " 'ndindex',\n",
       " 'nditer',\n",
       " 'negative',\n",
       " 'nested_iters',\n",
       " 'newaxis',\n",
       " 'nextafter',\n",
       " 'nonzero',\n",
       " 'not_equal',\n",
       " 'nper',\n",
       " 'npv',\n",
       " 'numarray',\n",
       " 'number',\n",
       " 'obj2sctype',\n",
       " 'object',\n",
       " 'object0',\n",
       " 'object_',\n",
       " 'ogrid',\n",
       " 'oldnumeric',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'os',\n",
       " 'outer',\n",
       " 'packbits',\n",
       " 'pad',\n",
       " 'partition',\n",
       " 'percentile',\n",
       " 'pi',\n",
       " 'piecewise',\n",
       " 'place',\n",
       " 'pmt',\n",
       " 'poly',\n",
       " 'poly1d',\n",
       " 'polyadd',\n",
       " 'polyder',\n",
       " 'polydiv',\n",
       " 'polyfit',\n",
       " 'polyint',\n",
       " 'polymul',\n",
       " 'polynomial',\n",
       " 'polysub',\n",
       " 'polyval',\n",
       " 'positive',\n",
       " 'power',\n",
       " 'ppmt',\n",
       " 'printoptions',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'promote_types',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'put_along_axis',\n",
       " 'putmask',\n",
       " 'pv',\n",
       " 'quantile',\n",
       " 'r_',\n",
       " 'rad2deg',\n",
       " 'radians',\n",
       " 'random',\n",
       " 'rate',\n",
       " 'ravel',\n",
       " 'ravel_multi_index',\n",
       " 'real',\n",
       " 'real_if_close',\n",
       " 'rec',\n",
       " 'recarray',\n",
       " 'recfromcsv',\n",
       " 'recfromtxt',\n",
       " 'reciprocal',\n",
       " 'record',\n",
       " 'remainder',\n",
       " 'repeat',\n",
       " 'require',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'result_type',\n",
       " 'right_shift',\n",
       " 'rint',\n",
       " 'roll',\n",
       " 'rollaxis',\n",
       " 'roots',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'row_stack',\n",
       " 's_',\n",
       " 'safe_eval',\n",
       " 'save',\n",
       " 'savetxt',\n",
       " 'savez',\n",
       " 'savez_compressed',\n",
       " 'sctype2char',\n",
       " 'sctypeDict',\n",
       " 'sctypeNA',\n",
       " 'sctypes',\n",
       " 'searchsorted',\n",
       " 'select',\n",
       " 'set_numeric_ops',\n",
       " 'set_printoptions',\n",
       " 'set_string_function',\n",
       " 'setbufsize',\n",
       " 'setdiff1d',\n",
       " 'seterr',\n",
       " 'seterrcall',\n",
       " 'seterrobj',\n",
       " 'setxor1d',\n",
       " 'shape',\n",
       " 'shares_memory',\n",
       " 'short',\n",
       " 'show_config',\n",
       " 'sign',\n",
       " 'signbit',\n",
       " 'signedinteger',\n",
       " 'sin',\n",
       " 'sinc',\n",
       " 'single',\n",
       " 'singlecomplex',\n",
       " 'sinh',\n",
       " 'size',\n",
       " 'sometrue',\n",
       " 'sort',\n",
       " 'sort_complex',\n",
       " 'source',\n",
       " 'spacing',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'str',\n",
       " 'str0',\n",
       " 'str_',\n",
       " 'string_',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'sys',\n",
       " 'take',\n",
       " 'take_along_axis',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensordot',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'tile',\n",
       " 'timedelta64',\n",
       " 'trace',\n",
       " 'tracemalloc_domain',\n",
       " 'transpose',\n",
       " 'trapz',\n",
       " 'tri',\n",
       " 'tril',\n",
       " 'tril_indices',\n",
       " 'tril_indices_from',\n",
       " 'trim_zeros',\n",
       " 'triu',\n",
       " 'triu_indices',\n",
       " 'triu_indices_from',\n",
       " 'true_divide',\n",
       " 'trunc',\n",
       " 'typeDict',\n",
       " 'typeNA',\n",
       " 'typecodes',\n",
       " 'typename',\n",
       " 'ubyte',\n",
       " 'ufunc',\n",
       " 'uint',\n",
       " 'uint0',\n",
       " 'uint16',\n",
       " 'uint32',\n",
       " 'uint64',\n",
       " 'uint8',\n",
       " 'uintc',\n",
       " 'uintp',\n",
       " 'ulonglong',\n",
       " 'unicode',\n",
       " 'unicode_',\n",
       " 'union1d',\n",
       " 'unique',\n",
       " 'unpackbits',\n",
       " 'unravel_index',\n",
       " 'unsignedinteger',\n",
       " 'unwrap',\n",
       " 'use_hugepage',\n",
       " 'ushort',\n",
       " 'vander',\n",
       " 'var',\n",
       " 'vdot',\n",
       " 'vectorize',\n",
       " 'version',\n",
       " 'void',\n",
       " 'void0',\n",
       " 'vsplit',\n",
       " 'vstack',\n",
       " 'w',\n",
       " 'warnings',\n",
       " 'where',\n",
       " 'who',\n",
       " 'zeros',\n",
       " 'zeros_like']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package numpy.linalg in numpy:\n",
      "\n",
      "NAME\n",
      "    numpy.linalg\n",
      "\n",
      "DESCRIPTION\n",
      "    ``numpy.linalg``\n",
      "    ================\n",
      "    \n",
      "    The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient\n",
      "    low level implementations of standard linear algebra algorithms. Those\n",
      "    libraries may be provided by NumPy itself using C versions of a subset of their\n",
      "    reference implementations but, when possible, highly optimized libraries that\n",
      "    take advantage of specialized processor functionality are preferred. Examples\n",
      "    of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries\n",
      "    are multithreaded and processor dependent, environmental variables and external\n",
      "    packages such as threadpoolctl may be needed to control the number of threads\n",
      "    or specify the processor architecture.\n",
      "    \n",
      "    - OpenBLAS: https://www.openblas.net/\n",
      "    - threadpoolctl: https://github.com/joblib/threadpoolctl\n",
      "    \n",
      "    Please note that the most-used linear algebra functions in NumPy are present in\n",
      "    the main ``numpy`` namespace rather than in ``numpy.linalg``.  There are:\n",
      "    ``dot``, ``vdot``, ``inner``, ``outer``, ``matmul``, ``tensordot``, ``einsum``,\n",
      "    ``einsum_path`` and ``kron``.\n",
      "    \n",
      "    Functions present in numpy.linalg are listed below.\n",
      "    \n",
      "    \n",
      "    Matrix and vector products\n",
      "    --------------------------\n",
      "    \n",
      "       multi_dot\n",
      "       matrix_power\n",
      "    \n",
      "    Decompositions\n",
      "    --------------\n",
      "    \n",
      "       cholesky\n",
      "       qr\n",
      "       svd\n",
      "    \n",
      "    Matrix eigenvalues\n",
      "    ------------------\n",
      "    \n",
      "       eig\n",
      "       eigh\n",
      "       eigvals\n",
      "       eigvalsh\n",
      "    \n",
      "    Norms and other numbers\n",
      "    -----------------------\n",
      "    \n",
      "       norm\n",
      "       cond\n",
      "       det\n",
      "       matrix_rank\n",
      "       slogdet\n",
      "    \n",
      "    Solving equations and inverting matrices\n",
      "    ----------------------------------------\n",
      "    \n",
      "       solve\n",
      "       tensorsolve\n",
      "       lstsq\n",
      "       inv\n",
      "       pinv\n",
      "       tensorinv\n",
      "    \n",
      "    Exceptions\n",
      "    ----------\n",
      "    \n",
      "       LinAlgError\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _umath_linalg\n",
      "    lapack_lite\n",
      "    linalg\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        LinAlgError\n",
      "    \n",
      "    class LinAlgError(builtins.Exception)\n",
      "     |  Generic Python-exception-derived object raised by linalg functions.\n",
      "     |  \n",
      "     |  General purpose exception class, derived from Python's exception.Exception\n",
      "     |  class, programmatically raised in linalg functions when a Linear\n",
      "     |  Algebra-related condition would prevent further correct execution of the\n",
      "     |  function.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  None\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from numpy import linalg as LA\n",
      "     |  >>> LA.inv(np.zeros((2,2)))\n",
      "     |  Traceback (most recent call last):\n",
      "     |    File \"<stdin>\", line 1, in <module>\n",
      "     |    File \"...linalg.py\", line 350,\n",
      "     |      in inv return wrap(solve(a, identity(a.shape[0], dtype=a.dtype)))\n",
      "     |    File \"...linalg.py\", line 249,\n",
      "     |      in solve\n",
      "     |      raise LinAlgError('Singular matrix')\n",
      "     |  numpy.linalg.LinAlgError: Singular matrix\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinAlgError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    cholesky(a)\n",
      "        Cholesky decomposition.\n",
      "        \n",
      "        Return the Cholesky decomposition, `L * L.H`, of the square matrix `a`,\n",
      "        where `L` is lower-triangular and .H is the conjugate transpose operator\n",
      "        (which is the ordinary transpose if `a` is real-valued).  `a` must be\n",
      "        Hermitian (symmetric if real-valued) and positive-definite. No\n",
      "        checking is performed to verify whether `a` is Hermitian or not.\n",
      "        In addition, only the lower-triangular and diagonal elements of `a`\n",
      "        are used. Only `L` is actually returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Hermitian (symmetric if all elements are real), positive-definite\n",
      "            input matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        L : (..., M, M) array_like\n",
      "            Upper or lower-triangular Cholesky factor of `a`.  Returns a\n",
      "            matrix object if `a` is a matrix object.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "           If the decomposition fails, for example, if `a` is not\n",
      "           positive-definite.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.cholesky : Similar function in SciPy.\n",
      "        scipy.linalg.cholesky_banded : Cholesky decompose a banded Hermitian\n",
      "                                       positive-definite matrix.\n",
      "        scipy.linalg.cho_factor : Cholesky decomposition of a matrix, to use in\n",
      "                                  `scipy.linalg.cho_solve`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The Cholesky decomposition is often used as a fast way of solving\n",
      "        \n",
      "        .. math:: A \\mathbf{x} = \\mathbf{b}\n",
      "        \n",
      "        (when `A` is both Hermitian/symmetric and positive-definite).\n",
      "        \n",
      "        First, we solve for :math:`\\mathbf{y}` in\n",
      "        \n",
      "        .. math:: L \\mathbf{y} = \\mathbf{b},\n",
      "        \n",
      "        and then for :math:`\\mathbf{x}` in\n",
      "        \n",
      "        .. math:: L.H \\mathbf{x} = \\mathbf{y}.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> A = np.array([[1,-2j],[2j,5]])\n",
      "        >>> A\n",
      "        array([[ 1.+0.j, -0.-2.j],\n",
      "               [ 0.+2.j,  5.+0.j]])\n",
      "        >>> L = np.linalg.cholesky(A)\n",
      "        >>> L\n",
      "        array([[1.+0.j, 0.+0.j],\n",
      "               [0.+2.j, 1.+0.j]])\n",
      "        >>> np.dot(L, L.T.conj()) # verify that L * L.H = A\n",
      "        array([[1.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 5.+0.j]])\n",
      "        >>> A = [[1,-2j],[2j,5]] # what happens if A is only array_like?\n",
      "        >>> np.linalg.cholesky(A) # an ndarray object is returned\n",
      "        array([[1.+0.j, 0.+0.j],\n",
      "               [0.+2.j, 1.+0.j]])\n",
      "        >>> # But a matrix object is returned if A is a matrix object\n",
      "        >>> np.linalg.cholesky(np.matrix(A))\n",
      "        matrix([[ 1.+0.j,  0.+0.j],\n",
      "                [ 0.+2.j,  1.+0.j]])\n",
      "    \n",
      "    cond(x, p=None)\n",
      "        Compute the condition number of a matrix.\n",
      "        \n",
      "        This function is capable of returning the condition number using\n",
      "        one of seven different norms, depending on the value of `p` (see\n",
      "        Parameters below).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (..., M, N) array_like\n",
      "            The matrix whose condition number is sought.\n",
      "        p : {None, 1, -1, 2, -2, inf, -inf, 'fro'}, optional\n",
      "            Order of the norm:\n",
      "        \n",
      "            =====  ============================\n",
      "            p      norm for matrices\n",
      "            =====  ============================\n",
      "            None   2-norm, computed directly using the ``SVD``\n",
      "            'fro'  Frobenius norm\n",
      "            inf    max(sum(abs(x), axis=1))\n",
      "            -inf   min(sum(abs(x), axis=1))\n",
      "            1      max(sum(abs(x), axis=0))\n",
      "            -1     min(sum(abs(x), axis=0))\n",
      "            2      2-norm (largest sing. value)\n",
      "            -2     smallest singular value\n",
      "            =====  ============================\n",
      "        \n",
      "            inf means the numpy.inf object, and the Frobenius norm is\n",
      "            the root-of-sum-of-squares norm.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        c : {float, inf}\n",
      "            The condition number of the matrix. May be infinite.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.linalg.norm\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The condition number of `x` is defined as the norm of `x` times the\n",
      "        norm of the inverse of `x` [1]_; the norm can be the usual L2-norm\n",
      "        (root-of-sum-of-squares) or one of a number of other matrix norms.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, Orlando, FL,\n",
      "               Academic Press, Inc., 1980, pg. 285.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])\n",
      "        >>> a\n",
      "        array([[ 1,  0, -1],\n",
      "               [ 0,  1,  0],\n",
      "               [ 1,  0,  1]])\n",
      "        >>> LA.cond(a)\n",
      "        1.4142135623730951\n",
      "        >>> LA.cond(a, 'fro')\n",
      "        3.1622776601683795\n",
      "        >>> LA.cond(a, np.inf)\n",
      "        2.0\n",
      "        >>> LA.cond(a, -np.inf)\n",
      "        1.0\n",
      "        >>> LA.cond(a, 1)\n",
      "        2.0\n",
      "        >>> LA.cond(a, -1)\n",
      "        1.0\n",
      "        >>> LA.cond(a, 2)\n",
      "        1.4142135623730951\n",
      "        >>> LA.cond(a, -2)\n",
      "        0.70710678118654746 # may vary\n",
      "        >>> min(LA.svd(a, compute_uv=False))*min(LA.svd(LA.inv(a), compute_uv=False))\n",
      "        0.70710678118654746 # may vary\n",
      "    \n",
      "    det(a)\n",
      "        Compute the determinant of an array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Input array to compute determinants for.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        det : (...) array_like\n",
      "            Determinant of `a`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        slogdet : Another way to represent the determinant, more suitable\n",
      "          for large matrices where underflow/overflow may occur.\n",
      "        scipy.linalg.det : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The determinant is computed via LU factorization using the LAPACK\n",
      "        routine ``z/dgetrf``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:\n",
      "        \n",
      "        >>> a = np.array([[1, 2], [3, 4]])\n",
      "        >>> np.linalg.det(a)\n",
      "        -2.0 # may vary\n",
      "        \n",
      "        Computing determinants for a stack of matrices:\n",
      "        \n",
      "        >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])\n",
      "        >>> a.shape\n",
      "        (3, 2, 2)\n",
      "        >>> np.linalg.det(a)\n",
      "        array([-2., -3., -8.])\n",
      "    \n",
      "    eig(a)\n",
      "        Compute the eigenvalues and right eigenvectors of a square array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array\n",
      "            Matrices for which the eigenvalues and right eigenvectors will\n",
      "            be computed\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M) array\n",
      "            The eigenvalues, each repeated according to its multiplicity.\n",
      "            The eigenvalues are not necessarily ordered. The resulting\n",
      "            array will be of complex type, unless the imaginary part is\n",
      "            zero in which case it will be cast to a real type. When `a`\n",
      "            is real the resulting eigenvalues will be real (0 imaginary\n",
      "            part) or occur in conjugate pairs\n",
      "        \n",
      "        v : (..., M, M) array\n",
      "            The normalized (unit \"length\") eigenvectors, such that the\n",
      "            column ``v[:,i]`` is the eigenvector corresponding to the\n",
      "            eigenvalue ``w[i]``.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigvals : eigenvalues of a non-symmetric array.\n",
      "        eigh : eigenvalues and eigenvectors of a real symmetric or complex\n",
      "               Hermitian (conjugate symmetric) array.\n",
      "        eigvalsh : eigenvalues of a real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) array.\n",
      "        scipy.linalg.eig : Similar function in SciPy that also solves the\n",
      "                           generalized eigenvalue problem.\n",
      "        scipy.linalg.schur : Best choice for unitary and other non-Hermitian\n",
      "                             normal matrices.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        This is implemented using the ``_geev`` LAPACK routines which compute\n",
      "        the eigenvalues and eigenvectors of general square arrays.\n",
      "        \n",
      "        The number `w` is an eigenvalue of `a` if there exists a vector\n",
      "        `v` such that ``a @ v = w * v``. Thus, the arrays `a`, `w`, and\n",
      "        `v` satisfy the equations ``a @ v[:,i] = w[i] * v[:,i]``\n",
      "        for :math:`i \\in \\{0,...,M-1\\}`.\n",
      "        \n",
      "        The array `v` of eigenvectors may not be of maximum rank, that is, some\n",
      "        of the columns may be linearly dependent, although round-off error may\n",
      "        obscure that fact. If the eigenvalues are all different, then theoretically\n",
      "        the eigenvectors are linearly independent and `a` can be diagonalized by\n",
      "        a similarity transformation using `v`, i.e, ``inv(v) @ a @ v`` is diagonal.\n",
      "        \n",
      "        For non-Hermitian normal matrices the SciPy function `scipy.linalg.schur`\n",
      "        is preferred because the matrix `v` is guaranteed to be unitary, which is\n",
      "        not the case when using `eig`. The Schur factorization produces an\n",
      "        upper triangular matrix rather than a diagonal matrix, but for normal\n",
      "        matrices only the diagonal of the upper triangular matrix is needed, the\n",
      "        rest is roundoff error.\n",
      "        \n",
      "        Finally, it is emphasized that `v` consists of the *right* (as in\n",
      "        right-hand side) eigenvectors of `a`.  A vector `y` satisfying\n",
      "        ``y.T @ a = z * y.T`` for some number `z` is called a *left*\n",
      "        eigenvector of `a`, and, in general, the left and right eigenvectors\n",
      "        of a matrix are not necessarily the (perhaps conjugate) transposes\n",
      "        of each other.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL,\n",
      "        Academic Press, Inc., 1980, Various pp.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        \n",
      "        (Almost) trivial example with real e-values and e-vectors.\n",
      "        \n",
      "        >>> w, v = LA.eig(np.diag((1, 2, 3)))\n",
      "        >>> w; v\n",
      "        array([1., 2., 3.])\n",
      "        array([[1., 0., 0.],\n",
      "               [0., 1., 0.],\n",
      "               [0., 0., 1.]])\n",
      "        \n",
      "        Real matrix possessing complex e-values and e-vectors; note that the\n",
      "        e-values are complex conjugates of each other.\n",
      "        \n",
      "        >>> w, v = LA.eig(np.array([[1, -1], [1, 1]]))\n",
      "        >>> w; v\n",
      "        array([1.+1.j, 1.-1.j])\n",
      "        array([[0.70710678+0.j        , 0.70710678-0.j        ],\n",
      "               [0.        -0.70710678j, 0.        +0.70710678j]])\n",
      "        \n",
      "        Complex-valued matrix with real e-values (but complex-valued e-vectors);\n",
      "        note that ``a.conj().T == a``, i.e., `a` is Hermitian.\n",
      "        \n",
      "        >>> a = np.array([[1, 1j], [-1j, 1]])\n",
      "        >>> w, v = LA.eig(a)\n",
      "        >>> w; v\n",
      "        array([2.+0.j, 0.+0.j])\n",
      "        array([[ 0.        +0.70710678j,  0.70710678+0.j        ], # may vary\n",
      "               [ 0.70710678+0.j        , -0.        +0.70710678j]])\n",
      "        \n",
      "        Be careful about round-off error!\n",
      "        \n",
      "        >>> a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]])\n",
      "        >>> # Theor. e-values are 1 +/- 1e-9\n",
      "        >>> w, v = LA.eig(a)\n",
      "        >>> w; v\n",
      "        array([1., 1.])\n",
      "        array([[1., 0.],\n",
      "               [0., 1.]])\n",
      "    \n",
      "    eigh(a, UPLO='L')\n",
      "        Return the eigenvalues and eigenvectors of a complex Hermitian\n",
      "        (conjugate symmetric) or a real symmetric matrix.\n",
      "        \n",
      "        Returns two objects, a 1-D array containing the eigenvalues of `a`, and\n",
      "        a 2-D square array or matrix (depending on the input type) of the\n",
      "        corresponding eigenvectors (in columns).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array\n",
      "            Hermitian or real symmetric matrices whose eigenvalues and\n",
      "            eigenvectors are to be computed.\n",
      "        UPLO : {'L', 'U'}, optional\n",
      "            Specifies whether the calculation is done with the lower triangular\n",
      "            part of `a` ('L', default) or the upper triangular part ('U').\n",
      "            Irrespective of this value only the real parts of the diagonal will\n",
      "            be considered in the computation to preserve the notion of a Hermitian\n",
      "            matrix. It therefore follows that the imaginary part of the diagonal\n",
      "            will always be treated as zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M) ndarray\n",
      "            The eigenvalues in ascending order, each repeated according to\n",
      "            its multiplicity.\n",
      "        v : {(..., M, M) ndarray, (..., M, M) matrix}\n",
      "            The column ``v[:, i]`` is the normalized eigenvector corresponding\n",
      "            to the eigenvalue ``w[i]``.  Will return a matrix object if `a` is\n",
      "            a matrix object.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigvalsh : eigenvalues of real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) arrays.\n",
      "        eig : eigenvalues and right eigenvectors for non-symmetric arrays.\n",
      "        eigvals : eigenvalues of non-symmetric arrays.\n",
      "        scipy.linalg.eigh : Similar function in SciPy (but also solves the\n",
      "                            generalized eigenvalue problem).\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The eigenvalues/eigenvectors are computed using LAPACK routines ``_syevd``,\n",
      "        ``_heevd``.\n",
      "        \n",
      "        The eigenvalues of real symmetric or complex Hermitian matrices are\n",
      "        always real. [1]_ The array `v` of (column) eigenvectors is unitary\n",
      "        and `a`, `w`, and `v` satisfy the equations\n",
      "        ``dot(a, v[:, i]) = w[i] * v[:, i]``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pg. 222.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, -2j], [2j, 5]])\n",
      "        >>> a\n",
      "        array([[ 1.+0.j, -0.-2.j],\n",
      "               [ 0.+2.j,  5.+0.j]])\n",
      "        >>> w, v = LA.eigh(a)\n",
      "        >>> w; v\n",
      "        array([0.17157288, 5.82842712])\n",
      "        array([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary\n",
      "               [ 0.        +0.38268343j,  0.        -0.92387953j]])\n",
      "        \n",
      "        >>> np.dot(a, v[:, 0]) - w[0] * v[:, 0] # verify 1st e-val/vec pair\n",
      "        array([5.55111512e-17+0.0000000e+00j, 0.00000000e+00+1.2490009e-16j])\n",
      "        >>> np.dot(a, v[:, 1]) - w[1] * v[:, 1] # verify 2nd e-val/vec pair\n",
      "        array([0.+0.j, 0.+0.j])\n",
      "        \n",
      "        >>> A = np.matrix(a) # what happens if input is a matrix object\n",
      "        >>> A\n",
      "        matrix([[ 1.+0.j, -0.-2.j],\n",
      "                [ 0.+2.j,  5.+0.j]])\n",
      "        >>> w, v = LA.eigh(A)\n",
      "        >>> w; v\n",
      "        array([0.17157288, 5.82842712])\n",
      "        matrix([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary\n",
      "                [ 0.        +0.38268343j,  0.        -0.92387953j]])\n",
      "        \n",
      "        >>> # demonstrate the treatment of the imaginary part of the diagonal\n",
      "        >>> a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])\n",
      "        >>> a\n",
      "        array([[5.+2.j, 9.-2.j],\n",
      "               [0.+2.j, 2.-1.j]])\n",
      "        >>> # with UPLO='L' this is numerically equivalent to using LA.eig() with:\n",
      "        >>> b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])\n",
      "        >>> b\n",
      "        array([[5.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 2.+0.j]])\n",
      "        >>> wa, va = LA.eigh(a)\n",
      "        >>> wb, vb = LA.eig(b)\n",
      "        >>> wa; wb\n",
      "        array([1., 6.])\n",
      "        array([6.+0.j, 1.+0.j])\n",
      "        >>> va; vb\n",
      "        array([[-0.4472136 +0.j        , -0.89442719+0.j        ], # may vary\n",
      "               [ 0.        +0.89442719j,  0.        -0.4472136j ]])\n",
      "        array([[ 0.89442719+0.j       , -0.        +0.4472136j],\n",
      "               [-0.        +0.4472136j,  0.89442719+0.j       ]])\n",
      "    \n",
      "    eigvals(a)\n",
      "        Compute the eigenvalues of a general matrix.\n",
      "        \n",
      "        Main difference between `eigvals` and `eig`: the eigenvectors aren't\n",
      "        returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            A complex- or real-valued matrix whose eigenvalues will be computed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M,) ndarray\n",
      "            The eigenvalues, each repeated according to its multiplicity.\n",
      "            They are not necessarily ordered, nor are they necessarily\n",
      "            real for real matrices.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eig : eigenvalues and right eigenvectors of general arrays\n",
      "        eigvalsh : eigenvalues of real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) arrays.\n",
      "        eigh : eigenvalues and eigenvectors of real symmetric or complex\n",
      "               Hermitian (conjugate symmetric) arrays.\n",
      "        scipy.linalg.eigvals : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        This is implemented using the ``_geev`` LAPACK routines which compute\n",
      "        the eigenvalues and eigenvectors of general square arrays.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Illustration, using the fact that the eigenvalues of a diagonal matrix\n",
      "        are its diagonal elements, that multiplying a matrix on the left\n",
      "        by an orthogonal matrix, `Q`, and on the right by `Q.T` (the transpose\n",
      "        of `Q`), preserves the eigenvalues of the \"middle\" matrix.  In other words,\n",
      "        if `Q` is orthogonal, then ``Q * A * Q.T`` has the same eigenvalues as\n",
      "        ``A``:\n",
      "        \n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> x = np.random.random()\n",
      "        >>> Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])\n",
      "        >>> LA.norm(Q[0, :]), LA.norm(Q[1, :]), np.dot(Q[0, :],Q[1, :])\n",
      "        (1.0, 1.0, 0.0)\n",
      "        \n",
      "        Now multiply a diagonal matrix by ``Q`` on one side and by ``Q.T`` on the other:\n",
      "        \n",
      "        >>> D = np.diag((-1,1))\n",
      "        >>> LA.eigvals(D)\n",
      "        array([-1.,  1.])\n",
      "        >>> A = np.dot(Q, D)\n",
      "        >>> A = np.dot(A, Q.T)\n",
      "        >>> LA.eigvals(A)\n",
      "        array([ 1., -1.]) # random\n",
      "    \n",
      "    eigvalsh(a, UPLO='L')\n",
      "        Compute the eigenvalues of a complex Hermitian or real symmetric matrix.\n",
      "        \n",
      "        Main difference from eigh: the eigenvectors are not computed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            A complex- or real-valued matrix whose eigenvalues are to be\n",
      "            computed.\n",
      "        UPLO : {'L', 'U'}, optional\n",
      "            Specifies whether the calculation is done with the lower triangular\n",
      "            part of `a` ('L', default) or the upper triangular part ('U').\n",
      "            Irrespective of this value only the real parts of the diagonal will\n",
      "            be considered in the computation to preserve the notion of a Hermitian\n",
      "            matrix. It therefore follows that the imaginary part of the diagonal\n",
      "            will always be treated as zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M,) ndarray\n",
      "            The eigenvalues in ascending order, each repeated according to\n",
      "            its multiplicity.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigh : eigenvalues and eigenvectors of real symmetric or complex Hermitian\n",
      "               (conjugate symmetric) arrays.\n",
      "        eigvals : eigenvalues of general real or complex arrays.\n",
      "        eig : eigenvalues and right eigenvectors of general real or complex\n",
      "              arrays.\n",
      "        scipy.linalg.eigvalsh : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The eigenvalues are computed using LAPACK routines ``_syevd``, ``_heevd``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, -2j], [2j, 5]])\n",
      "        >>> LA.eigvalsh(a)\n",
      "        array([ 0.17157288,  5.82842712]) # may vary\n",
      "        \n",
      "        >>> # demonstrate the treatment of the imaginary part of the diagonal\n",
      "        >>> a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])\n",
      "        >>> a\n",
      "        array([[5.+2.j, 9.-2.j],\n",
      "               [0.+2.j, 2.-1.j]])\n",
      "        >>> # with UPLO='L' this is numerically equivalent to using LA.eigvals()\n",
      "        >>> # with:\n",
      "        >>> b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])\n",
      "        >>> b\n",
      "        array([[5.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 2.+0.j]])\n",
      "        >>> wa = LA.eigvalsh(a)\n",
      "        >>> wb = LA.eigvals(b)\n",
      "        >>> wa; wb\n",
      "        array([1., 6.])\n",
      "        array([6.+0.j, 1.+0.j])\n",
      "    \n",
      "    inv(a)\n",
      "        Compute the (multiplicative) inverse of a matrix.\n",
      "        \n",
      "        Given a square matrix `a`, return the matrix `ainv` satisfying\n",
      "        ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Matrix to be inverted.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ainv : (..., M, M) ndarray or matrix\n",
      "            (Multiplicative) inverse of the matrix `a`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is not square or inversion fails.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.inv : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import inv\n",
      "        >>> a = np.array([[1., 2.], [3., 4.]])\n",
      "        >>> ainv = inv(a)\n",
      "        >>> np.allclose(np.dot(a, ainv), np.eye(2))\n",
      "        True\n",
      "        >>> np.allclose(np.dot(ainv, a), np.eye(2))\n",
      "        True\n",
      "        \n",
      "        If a is a matrix object, then the return value is a matrix as well:\n",
      "        \n",
      "        >>> ainv = inv(np.matrix(a))\n",
      "        >>> ainv\n",
      "        matrix([[-2. ,  1. ],\n",
      "                [ 1.5, -0.5]])\n",
      "        \n",
      "        Inverses of several matrices can be computed at once:\n",
      "        \n",
      "        >>> a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])\n",
      "        >>> inv(a)\n",
      "        array([[[-2.  ,  1.  ],\n",
      "                [ 1.5 , -0.5 ]],\n",
      "               [[-1.25,  0.75],\n",
      "                [ 0.75, -0.25]]])\n",
      "    \n",
      "    lstsq(a, b, rcond='warn')\n",
      "        Return the least-squares solution to a linear matrix equation.\n",
      "        \n",
      "        Computes the vector x that approximatively solves the equation\n",
      "        ``a @ x = b``. The equation may be under-, well-, or over-determined\n",
      "        (i.e., the number of linearly independent rows of `a` can be less than,\n",
      "        equal to, or greater than its number of linearly independent columns).\n",
      "        If `a` is square and of full rank, then `x` (but for round-off error)\n",
      "        is the \"exact\" solution of the equation. Else, `x` minimizes the\n",
      "        Euclidean 2-norm :math:`|| b - a x ||`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (M, N) array_like\n",
      "            \"Coefficient\" matrix.\n",
      "        b : {(M,), (M, K)} array_like\n",
      "            Ordinate or \"dependent variable\" values. If `b` is two-dimensional,\n",
      "            the least-squares solution is calculated for each of the `K` columns\n",
      "            of `b`.\n",
      "        rcond : float, optional\n",
      "            Cut-off ratio for small singular values of `a`.\n",
      "            For the purposes of rank determination, singular values are treated\n",
      "            as zero if they are smaller than `rcond` times the largest singular\n",
      "            value of `a`.\n",
      "        \n",
      "            .. versionchanged:: 1.14.0\n",
      "               If not set, a FutureWarning is given. The previous default\n",
      "               of ``-1`` will use the machine precision as `rcond` parameter,\n",
      "               the new default will use the machine precision times `max(M, N)`.\n",
      "               To silence the warning and use the new default, use ``rcond=None``,\n",
      "               to keep using the old behavior, use ``rcond=-1``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {(N,), (N, K)} ndarray\n",
      "            Least-squares solution. If `b` is two-dimensional,\n",
      "            the solutions are in the `K` columns of `x`.\n",
      "        residuals : {(1,), (K,), (0,)} ndarray\n",
      "            Sums of residuals; squared Euclidean 2-norm for each column in\n",
      "            ``b - a*x``.\n",
      "            If the rank of `a` is < N or M <= N, this is an empty array.\n",
      "            If `b` is 1-dimensional, this is a (1,) shape array.\n",
      "            Otherwise the shape is (K,).\n",
      "        rank : int\n",
      "            Rank of matrix `a`.\n",
      "        s : (min(M, N),) ndarray\n",
      "            Singular values of `a`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.lstsq : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If `b` is a matrix, then all array results are returned as matrices.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Fit a line, ``y = mx + c``, through some noisy data-points:\n",
      "        \n",
      "        >>> x = np.array([0, 1, 2, 3])\n",
      "        >>> y = np.array([-1, 0.2, 0.9, 2.1])\n",
      "        \n",
      "        By examining the coefficients, we see that the line should have a\n",
      "        gradient of roughly 1 and cut the y-axis at, more or less, -1.\n",
      "        \n",
      "        We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``\n",
      "        and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:\n",
      "        \n",
      "        >>> A = np.vstack([x, np.ones(len(x))]).T\n",
      "        >>> A\n",
      "        array([[ 0.,  1.],\n",
      "               [ 1.,  1.],\n",
      "               [ 2.,  1.],\n",
      "               [ 3.,  1.]])\n",
      "        \n",
      "        >>> m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
      "        >>> m, c\n",
      "        (1.0 -0.95) # may vary\n",
      "        \n",
      "        Plot the data along with the fitted line:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> _ = plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
      "        >>> _ = plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
      "        >>> _ = plt.legend()\n",
      "        >>> plt.show()\n",
      "    \n",
      "    matrix_power(a, n)\n",
      "        Raise a square matrix to the (integer) power `n`.\n",
      "        \n",
      "        For positive integers `n`, the power is computed by repeated matrix\n",
      "        squarings and matrix multiplications. If ``n == 0``, the identity matrix\n",
      "        of the same shape as M is returned. If ``n < 0``, the inverse\n",
      "        is computed and then raised to the ``abs(n)``.\n",
      "        \n",
      "        .. note:: Stacks of object matrices are not currently supported.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Matrix to be \"powered\".\n",
      "        n : int\n",
      "            The exponent can be any integer or long integer, positive,\n",
      "            negative, or zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        a**n : (..., M, M) ndarray or matrix object\n",
      "            The return value is the same shape and type as `M`;\n",
      "            if the exponent is positive or zero then the type of the\n",
      "            elements is the same as those of `M`. If the exponent is\n",
      "            negative the elements are floating-point.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            For matrices that are not square or that (for negative powers) cannot\n",
      "            be inverted numerically.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import matrix_power\n",
      "        >>> i = np.array([[0, 1], [-1, 0]]) # matrix equiv. of the imaginary unit\n",
      "        >>> matrix_power(i, 3) # should = -i\n",
      "        array([[ 0, -1],\n",
      "               [ 1,  0]])\n",
      "        >>> matrix_power(i, 0)\n",
      "        array([[1, 0],\n",
      "               [0, 1]])\n",
      "        >>> matrix_power(i, -3) # should = 1/(-i) = i, but w/ f.p. elements\n",
      "        array([[ 0.,  1.],\n",
      "               [-1.,  0.]])\n",
      "        \n",
      "        Somewhat more sophisticated example\n",
      "        \n",
      "        >>> q = np.zeros((4, 4))\n",
      "        >>> q[0:2, 0:2] = -i\n",
      "        >>> q[2:4, 2:4] = i\n",
      "        >>> q # one of the three quaternion units not equal to 1\n",
      "        array([[ 0., -1.,  0.,  0.],\n",
      "               [ 1.,  0.,  0.,  0.],\n",
      "               [ 0.,  0.,  0.,  1.],\n",
      "               [ 0.,  0., -1.,  0.]])\n",
      "        >>> matrix_power(q, 2) # = -np.eye(4)\n",
      "        array([[-1.,  0.,  0.,  0.],\n",
      "               [ 0., -1.,  0.,  0.],\n",
      "               [ 0.,  0., -1.,  0.],\n",
      "               [ 0.,  0.,  0., -1.]])\n",
      "    \n",
      "    matrix_rank(M, tol=None, hermitian=False)\n",
      "        Return matrix rank of array using SVD method\n",
      "        \n",
      "        Rank of the array is the number of singular values of the array that are\n",
      "        greater than `tol`.\n",
      "        \n",
      "        .. versionchanged:: 1.14\n",
      "           Can now operate on stacks of matrices\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        M : {(M,), (..., M, N)} array_like\n",
      "            Input vector or stack of matrices.\n",
      "        tol : (...) array_like, float, optional\n",
      "            Threshold below which SVD values are considered zero. If `tol` is\n",
      "            None, and ``S`` is an array with singular values for `M`, and\n",
      "            ``eps`` is the epsilon value for datatype of ``S``, then `tol` is\n",
      "            set to ``S.max() * max(M.shape) * eps``.\n",
      "        \n",
      "            .. versionchanged:: 1.14\n",
      "               Broadcasted against the stack of matrices\n",
      "        hermitian : bool, optional\n",
      "            If True, `M` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.14\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rank : (...) array_like\n",
      "            Rank of M.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default threshold to detect rank deficiency is a test on the magnitude\n",
      "        of the singular values of `M`.  By default, we identify singular values less\n",
      "        than ``S.max() * max(M.shape) * eps`` as indicating rank deficiency (with\n",
      "        the symbols defined above). This is the algorithm MATLAB uses [1].  It also\n",
      "        appears in *Numerical recipes* in the discussion of SVD solutions for linear\n",
      "        least squares [2].\n",
      "        \n",
      "        This default threshold is designed to detect rank deficiency accounting for\n",
      "        the numerical errors of the SVD computation.  Imagine that there is a column\n",
      "        in `M` that is an exact (in floating point) linear combination of other\n",
      "        columns in `M`. Computing the SVD on `M` will not produce a singular value\n",
      "        exactly equal to 0 in general: any difference of the smallest SVD value from\n",
      "        0 will be caused by numerical imprecision in the calculation of the SVD.\n",
      "        Our threshold for small SVD values takes this numerical imprecision into\n",
      "        account, and the default threshold will detect such numerical rank\n",
      "        deficiency.  The threshold may declare a matrix `M` rank deficient even if\n",
      "        the linear combination of some columns of `M` is not exactly equal to\n",
      "        another column of `M` but only numerically very close to another column of\n",
      "        `M`.\n",
      "        \n",
      "        We chose our default threshold because it is in wide use.  Other thresholds\n",
      "        are possible.  For example, elsewhere in the 2007 edition of *Numerical\n",
      "        recipes* there is an alternative threshold of ``S.max() *\n",
      "        np.finfo(M.dtype).eps / 2. * np.sqrt(m + n + 1.)``. The authors describe\n",
      "        this threshold as being based on \"expected roundoff error\" (p 71).\n",
      "        \n",
      "        The thresholds above deal with floating point roundoff error in the\n",
      "        calculation of the SVD.  However, you may have more information about the\n",
      "        sources of error in `M` that would make you consider other tolerance values\n",
      "        to detect *effective* rank deficiency.  The most useful measure of the\n",
      "        tolerance depends on the operations you intend to use on your matrix.  For\n",
      "        example, if your data come from uncertain measurements with uncertainties\n",
      "        greater than floating point epsilon, choosing a tolerance near that\n",
      "        uncertainty may be preferable.  The tolerance may be absolute if the\n",
      "        uncertainties are absolute rather than relative.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] MATLAB reference documention, \"Rank\"\n",
      "               https://www.mathworks.com/help/techdoc/ref/rank.html\n",
      "        .. [2] W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery,\n",
      "               \"Numerical Recipes (3rd edition)\", Cambridge University Press, 2007,\n",
      "               page 795.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import matrix_rank\n",
      "        >>> matrix_rank(np.eye(4)) # Full rank matrix\n",
      "        4\n",
      "        >>> I=np.eye(4); I[-1,-1] = 0. # rank deficient matrix\n",
      "        >>> matrix_rank(I)\n",
      "        3\n",
      "        >>> matrix_rank(np.ones((4,))) # 1 dimension - rank 1 unless all 0\n",
      "        1\n",
      "        >>> matrix_rank(np.zeros((4,)))\n",
      "        0\n",
      "    \n",
      "    multi_dot(arrays, *, out=None)\n",
      "        Compute the dot product of two or more arrays in a single function call,\n",
      "        while automatically selecting the fastest evaluation order.\n",
      "        \n",
      "        `multi_dot` chains `numpy.dot` and uses optimal parenthesization\n",
      "        of the matrices [1]_ [2]_. Depending on the shapes of the matrices,\n",
      "        this can speed up the multiplication a lot.\n",
      "        \n",
      "        If the first argument is 1-D it is treated as a row vector.\n",
      "        If the last argument is 1-D it is treated as a column vector.\n",
      "        The other arguments must be 2-D.\n",
      "        \n",
      "        Think of `multi_dot` as::\n",
      "        \n",
      "            def multi_dot(arrays): return functools.reduce(np.dot, arrays)\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        arrays : sequence of array_like\n",
      "            If the first argument is 1-D it is treated as row vector.\n",
      "            If the last argument is 1-D it is treated as column vector.\n",
      "            The other arguments must be 2-D.\n",
      "        out : ndarray, optional\n",
      "            Output argument. This must have the exact kind that would be returned\n",
      "            if it was not used. In particular, it must have the right type, must be\n",
      "            C-contiguous, and its dtype must be the dtype that would be returned\n",
      "            for `dot(a, b)`. This is a performance feature. Therefore, if these\n",
      "            conditions are not met, an exception is raised, instead of attempting\n",
      "            to be flexible.\n",
      "        \n",
      "            .. versionadded:: 1.19.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        output : ndarray\n",
      "            Returns the dot product of the supplied arrays.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        dot : dot multiplication with two arguments.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Cormen, \"Introduction to Algorithms\", Chapter 15.2, p. 370-378\n",
      "        .. [2] https://en.wikipedia.org/wiki/Matrix_chain_multiplication\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        `multi_dot` allows you to write::\n",
      "        \n",
      "        >>> from numpy.linalg import multi_dot\n",
      "        >>> # Prepare some data\n",
      "        >>> A = np.random.random((10000, 100))\n",
      "        >>> B = np.random.random((100, 1000))\n",
      "        >>> C = np.random.random((1000, 5))\n",
      "        >>> D = np.random.random((5, 333))\n",
      "        >>> # the actual dot multiplication\n",
      "        >>> _ = multi_dot([A, B, C, D])\n",
      "        \n",
      "        instead of::\n",
      "        \n",
      "        >>> _ = np.dot(np.dot(np.dot(A, B), C), D)\n",
      "        >>> # or\n",
      "        >>> _ = A.dot(B).dot(C).dot(D)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The cost for a matrix multiplication can be calculated with the\n",
      "        following function::\n",
      "        \n",
      "            def cost(A, B):\n",
      "                return A.shape[0] * A.shape[1] * B.shape[1]\n",
      "        \n",
      "        Assume we have three matrices\n",
      "        :math:`A_{10x100}, B_{100x5}, C_{5x50}`.\n",
      "        \n",
      "        The costs for the two different parenthesizations are as follows::\n",
      "        \n",
      "            cost((AB)C) = 10*100*5 + 10*5*50   = 5000 + 2500   = 7500\n",
      "            cost(A(BC)) = 10*100*50 + 100*5*50 = 50000 + 25000 = 75000\n",
      "    \n",
      "    norm(x, ord=None, axis=None, keepdims=False)\n",
      "        Matrix or vector norm.\n",
      "        \n",
      "        This function is able to return one of eight different matrix norms,\n",
      "        or one of an infinite number of vector norms (described below), depending\n",
      "        on the value of the ``ord`` parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.  If `axis` is None, `x` must be 1-D or 2-D, unless `ord`\n",
      "            is None. If both `axis` and `ord` are None, the 2-norm of\n",
      "            ``x.ravel`` will be returned.\n",
      "        ord : {non-zero int, inf, -inf, 'fro', 'nuc'}, optional\n",
      "            Order of the norm (see table under ``Notes``). inf means numpy's\n",
      "            `inf` object. The default is None.\n",
      "        axis : {None, int, 2-tuple of ints}, optional.\n",
      "            If `axis` is an integer, it specifies the axis of `x` along which to\n",
      "            compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
      "            axes that hold 2-D matrices, and the matrix norms of these matrices\n",
      "            are computed.  If `axis` is None then either a vector norm (when `x`\n",
      "            is 1-D) or a matrix norm (when `x` is 2-D) is returned. The default\n",
      "            is None.\n",
      "        \n",
      "            .. versionadded:: 1.8.0\n",
      "        \n",
      "        keepdims : bool, optional\n",
      "            If this is set to True, the axes which are normed over are left in the\n",
      "            result as dimensions with size one.  With this option the result will\n",
      "            broadcast correctly against the original `x`.\n",
      "        \n",
      "            .. versionadded:: 1.10.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n : float or ndarray\n",
      "            Norm of the matrix or vector(s).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.norm : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For values of ``ord < 1``, the result is, strictly speaking, not a\n",
      "        mathematical 'norm', but it may still be useful for various numerical\n",
      "        purposes.\n",
      "        \n",
      "        The following norms can be calculated:\n",
      "        \n",
      "        =====  ============================  ==========================\n",
      "        ord    norm for matrices             norm for vectors\n",
      "        =====  ============================  ==========================\n",
      "        None   Frobenius norm                2-norm\n",
      "        'fro'  Frobenius norm                --\n",
      "        'nuc'  nuclear norm                  --\n",
      "        inf    max(sum(abs(x), axis=1))      max(abs(x))\n",
      "        -inf   min(sum(abs(x), axis=1))      min(abs(x))\n",
      "        0      --                            sum(x != 0)\n",
      "        1      max(sum(abs(x), axis=0))      as below\n",
      "        -1     min(sum(abs(x), axis=0))      as below\n",
      "        2      2-norm (largest sing. value)  as below\n",
      "        -2     smallest singular value       as below\n",
      "        other  --                            sum(abs(x)**ord)**(1./ord)\n",
      "        =====  ============================  ==========================\n",
      "        \n",
      "        The Frobenius norm is given by [1]_:\n",
      "        \n",
      "            :math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
      "        \n",
      "        The nuclear norm is the sum of the singular values.\n",
      "        \n",
      "        Both the Frobenius and nuclear norm orders are only defined for\n",
      "        matrices and raise a ValueError when ``x.ndim != 2``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
      "               Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.arange(9) - 4\n",
      "        >>> a\n",
      "        array([-4, -3, -2, ...,  2,  3,  4])\n",
      "        >>> b = a.reshape((3, 3))\n",
      "        >>> b\n",
      "        array([[-4, -3, -2],\n",
      "               [-1,  0,  1],\n",
      "               [ 2,  3,  4]])\n",
      "        \n",
      "        >>> LA.norm(a)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b, 'fro')\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(a, np.inf)\n",
      "        4.0\n",
      "        >>> LA.norm(b, np.inf)\n",
      "        9.0\n",
      "        >>> LA.norm(a, -np.inf)\n",
      "        0.0\n",
      "        >>> LA.norm(b, -np.inf)\n",
      "        2.0\n",
      "        \n",
      "        >>> LA.norm(a, 1)\n",
      "        20.0\n",
      "        >>> LA.norm(b, 1)\n",
      "        7.0\n",
      "        >>> LA.norm(a, -1)\n",
      "        -4.6566128774142013e-010\n",
      "        >>> LA.norm(b, -1)\n",
      "        6.0\n",
      "        >>> LA.norm(a, 2)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b, 2)\n",
      "        7.3484692283495345\n",
      "        \n",
      "        >>> LA.norm(a, -2)\n",
      "        0.0\n",
      "        >>> LA.norm(b, -2)\n",
      "        1.8570331885190563e-016 # may vary\n",
      "        >>> LA.norm(a, 3)\n",
      "        5.8480354764257312 # may vary\n",
      "        >>> LA.norm(a, -3)\n",
      "        0.0\n",
      "        \n",
      "        Using the `axis` argument to compute vector norms:\n",
      "        \n",
      "        >>> c = np.array([[ 1, 2, 3],\n",
      "        ...               [-1, 1, 4]])\n",
      "        >>> LA.norm(c, axis=0)\n",
      "        array([ 1.41421356,  2.23606798,  5.        ])\n",
      "        >>> LA.norm(c, axis=1)\n",
      "        array([ 3.74165739,  4.24264069])\n",
      "        >>> LA.norm(c, ord=1, axis=1)\n",
      "        array([ 6.,  6.])\n",
      "        \n",
      "        Using the `axis` argument to compute matrix norms:\n",
      "        \n",
      "        >>> m = np.arange(8).reshape(2,2,2)\n",
      "        >>> LA.norm(m, axis=(1,2))\n",
      "        array([  3.74165739,  11.22497216])\n",
      "        >>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])\n",
      "        (3.7416573867739413, 11.224972160321824)\n",
      "    \n",
      "    pinv(a, rcond=1e-15, hermitian=False)\n",
      "        Compute the (Moore-Penrose) pseudo-inverse of a matrix.\n",
      "        \n",
      "        Calculate the generalized inverse of a matrix using its\n",
      "        singular-value decomposition (SVD) and including all\n",
      "        *large* singular values.\n",
      "        \n",
      "        .. versionchanged:: 1.14\n",
      "           Can now operate on stacks of matrices\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, N) array_like\n",
      "            Matrix or stack of matrices to be pseudo-inverted.\n",
      "        rcond : (...) array_like of float\n",
      "            Cutoff for small singular values.\n",
      "            Singular values less than or equal to\n",
      "            ``rcond * largest_singular_value`` are set to zero.\n",
      "            Broadcasts against the stack of matrices.\n",
      "        hermitian : bool, optional\n",
      "            If True, `a` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        B : (..., N, M) ndarray\n",
      "            The pseudo-inverse of `a`. If `a` is a `matrix` instance, then so\n",
      "            is `B`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the SVD computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.pinv : Similar function in SciPy.\n",
      "        scipy.linalg.pinv2 : Similar function in SciPy (SVD-based).\n",
      "        scipy.linalg.pinvh : Compute the (Moore-Penrose) pseudo-inverse of a\n",
      "                             Hermitian matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The pseudo-inverse of a matrix A, denoted :math:`A^+`, is\n",
      "        defined as: \"the matrix that 'solves' [the least-squares problem]\n",
      "        :math:`Ax = b`,\" i.e., if :math:`\\bar{x}` is said solution, then\n",
      "        :math:`A^+` is that matrix such that :math:`\\bar{x} = A^+b`.\n",
      "        \n",
      "        It can be shown that if :math:`Q_1 \\Sigma Q_2^T = A` is the singular\n",
      "        value decomposition of A, then\n",
      "        :math:`A^+ = Q_2 \\Sigma^+ Q_1^T`, where :math:`Q_{1,2}` are\n",
      "        orthogonal matrices, :math:`\\Sigma` is a diagonal matrix consisting\n",
      "        of A's so-called singular values, (followed, typically, by\n",
      "        zeros), and then :math:`\\Sigma^+` is simply the diagonal matrix\n",
      "        consisting of the reciprocals of A's singular values\n",
      "        (again, followed by zeros). [1]_\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pp. 139-142.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The following example checks that ``a * a+ * a == a`` and\n",
      "        ``a+ * a * a+ == a+``:\n",
      "        \n",
      "        >>> a = np.random.randn(9, 6)\n",
      "        >>> B = np.linalg.pinv(a)\n",
      "        >>> np.allclose(a, np.dot(a, np.dot(B, a)))\n",
      "        True\n",
      "        >>> np.allclose(B, np.dot(B, np.dot(a, B)))\n",
      "        True\n",
      "    \n",
      "    qr(a, mode='reduced')\n",
      "        Compute the qr factorization of a matrix.\n",
      "        \n",
      "        Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is\n",
      "        upper-triangular.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like, shape (M, N)\n",
      "            Matrix to be factored.\n",
      "        mode : {'reduced', 'complete', 'r', 'raw'}, optional\n",
      "            If K = min(M, N), then\n",
      "        \n",
      "            * 'reduced'  : returns q, r with dimensions (M, K), (K, N) (default)\n",
      "            * 'complete' : returns q, r with dimensions (M, M), (M, N)\n",
      "            * 'r'        : returns r only with dimensions (K, N)\n",
      "            * 'raw'      : returns h, tau with dimensions (N, M), (K,)\n",
      "        \n",
      "            The options 'reduced', 'complete, and 'raw' are new in numpy 1.8,\n",
      "            see the notes for more information. The default is 'reduced', and to\n",
      "            maintain backward compatibility with earlier versions of numpy both\n",
      "            it and the old default 'full' can be omitted. Note that array h\n",
      "            returned in 'raw' mode is transposed for calling Fortran. The\n",
      "            'economic' mode is deprecated.  The modes 'full' and 'economic' may\n",
      "            be passed using only the first letter for backwards compatibility,\n",
      "            but all others must be spelled out. See the Notes for more\n",
      "            explanation.\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        q : ndarray of float or complex, optional\n",
      "            A matrix with orthonormal columns. When mode = 'complete' the\n",
      "            result is an orthogonal/unitary matrix depending on whether or not\n",
      "            a is real/complex. The determinant may be either +/- 1 in that\n",
      "            case.\n",
      "        r : ndarray of float or complex, optional\n",
      "            The upper-triangular matrix.\n",
      "        (h, tau) : ndarrays of np.double or np.cdouble, optional\n",
      "            The array h contains the Householder reflectors that generate q\n",
      "            along with r. The tau array contains scaling factors for the\n",
      "            reflectors. In the deprecated  'economic' mode only h is returned.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If factoring fails.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.qr : Similar function in SciPy.\n",
      "        scipy.linalg.rq : Compute RQ decomposition of a matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is an interface to the LAPACK routines ``dgeqrf``, ``zgeqrf``,\n",
      "        ``dorgqr``, and ``zungqr``.\n",
      "        \n",
      "        For more information on the qr factorization, see for example:\n",
      "        https://en.wikipedia.org/wiki/QR_factorization\n",
      "        \n",
      "        Subclasses of `ndarray` are preserved except for the 'raw' mode. So if\n",
      "        `a` is of type `matrix`, all the return values will be matrices too.\n",
      "        \n",
      "        New 'reduced', 'complete', and 'raw' options for mode were added in\n",
      "        NumPy 1.8.0 and the old option 'full' was made an alias of 'reduced'.  In\n",
      "        addition the options 'full' and 'economic' were deprecated.  Because\n",
      "        'full' was the previous default and 'reduced' is the new default,\n",
      "        backward compatibility can be maintained by letting `mode` default.\n",
      "        The 'raw' option was added so that LAPACK routines that can multiply\n",
      "        arrays by q using the Householder reflectors can be used. Note that in\n",
      "        this case the returned arrays are of type np.double or np.cdouble and\n",
      "        the h array is transposed to be FORTRAN compatible.  No routines using\n",
      "        the 'raw' return are currently exposed by numpy, but some are available\n",
      "        in lapack_lite and just await the necessary work.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.random.randn(9, 6)\n",
      "        >>> q, r = np.linalg.qr(a)\n",
      "        >>> np.allclose(a, np.dot(q, r))  # a does equal qr\n",
      "        True\n",
      "        >>> r2 = np.linalg.qr(a, mode='r')\n",
      "        >>> np.allclose(r, r2)  # mode='r' returns the same r as mode='full'\n",
      "        True\n",
      "        \n",
      "        Example illustrating a common use of `qr`: solving of least squares\n",
      "        problems\n",
      "        \n",
      "        What are the least-squares-best `m` and `y0` in ``y = y0 + mx`` for\n",
      "        the following data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points\n",
      "        and you'll see that it should be y0 = 0, m = 1.)  The answer is provided\n",
      "        by solving the over-determined matrix equation ``Ax = b``, where::\n",
      "        \n",
      "          A = array([[0, 1], [1, 1], [1, 1], [2, 1]])\n",
      "          x = array([[y0], [m]])\n",
      "          b = array([[1], [0], [2], [1]])\n",
      "        \n",
      "        If A = qr such that q is orthonormal (which is always possible via\n",
      "        Gram-Schmidt), then ``x = inv(r) * (q.T) * b``.  (In numpy practice,\n",
      "        however, we simply use `lstsq`.)\n",
      "        \n",
      "        >>> A = np.array([[0, 1], [1, 1], [1, 1], [2, 1]])\n",
      "        >>> A\n",
      "        array([[0, 1],\n",
      "               [1, 1],\n",
      "               [1, 1],\n",
      "               [2, 1]])\n",
      "        >>> b = np.array([1, 0, 2, 1])\n",
      "        >>> q, r = np.linalg.qr(A)\n",
      "        >>> p = np.dot(q.T, b)\n",
      "        >>> np.dot(np.linalg.inv(r), p)\n",
      "        array([  1.1e-16,   1.0e+00])\n",
      "    \n",
      "    slogdet(a)\n",
      "        Compute the sign and (natural) logarithm of the determinant of an array.\n",
      "        \n",
      "        If an array has a very small or very large determinant, then a call to\n",
      "        `det` may overflow or underflow. This routine is more robust against such\n",
      "        issues, because it computes the logarithm of the determinant rather than\n",
      "        the determinant itself.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Input array, has to be a square 2-D array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        sign : (...) array_like\n",
      "            A number representing the sign of the determinant. For a real matrix,\n",
      "            this is 1, 0, or -1. For a complex matrix, this is a complex number\n",
      "            with absolute value 1 (i.e., it is on the unit circle), or else 0.\n",
      "        logdet : (...) array_like\n",
      "            The natural log of the absolute value of the determinant.\n",
      "        \n",
      "        If the determinant is zero, then `sign` will be 0 and `logdet` will be\n",
      "        -Inf. In all cases, the determinant is equal to ``sign * np.exp(logdet)``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        det\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        .. versionadded:: 1.6.0\n",
      "        \n",
      "        The determinant is computed via LU factorization using the LAPACK\n",
      "        routine ``z/dgetrf``.\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The determinant of a 2-D array ``[[a, b], [c, d]]`` is ``ad - bc``:\n",
      "        \n",
      "        >>> a = np.array([[1, 2], [3, 4]])\n",
      "        >>> (sign, logdet) = np.linalg.slogdet(a)\n",
      "        >>> (sign, logdet)\n",
      "        (-1, 0.69314718055994529) # may vary\n",
      "        >>> sign * np.exp(logdet)\n",
      "        -2.0\n",
      "        \n",
      "        Computing log-determinants for a stack of matrices:\n",
      "        \n",
      "        >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])\n",
      "        >>> a.shape\n",
      "        (3, 2, 2)\n",
      "        >>> sign, logdet = np.linalg.slogdet(a)\n",
      "        >>> (sign, logdet)\n",
      "        (array([-1., -1., -1.]), array([ 0.69314718,  1.09861229,  2.07944154]))\n",
      "        >>> sign * np.exp(logdet)\n",
      "        array([-2., -3., -8.])\n",
      "        \n",
      "        This routine succeeds where ordinary `det` does not:\n",
      "        \n",
      "        >>> np.linalg.det(np.eye(500) * 0.1)\n",
      "        0.0\n",
      "        >>> np.linalg.slogdet(np.eye(500) * 0.1)\n",
      "        (1, -1151.2925464970228)\n",
      "    \n",
      "    solve(a, b)\n",
      "        Solve a linear matrix equation, or system of linear scalar equations.\n",
      "        \n",
      "        Computes the \"exact\" solution, `x`, of the well-determined, i.e., full\n",
      "        rank, linear matrix equation `ax = b`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Coefficient matrix.\n",
      "        b : {(..., M,), (..., M, K)}, array_like\n",
      "            Ordinate or \"dependent variable\" values.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {(..., M,), (..., M, K)} ndarray\n",
      "            Solution to the system a x = b.  Returned shape is identical to `b`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not square.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.solve : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The solutions are computed using LAPACK routine ``_gesv``.\n",
      "        \n",
      "        `a` must be square and of full-rank, i.e., all rows (or, equivalently,\n",
      "        columns) must be linearly independent; if either is not true, use\n",
      "        `lstsq` for the least-squares best \"solution\" of the\n",
      "        system/equation.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pg. 22.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Solve the system of equations ``3 * x0 + x1 = 9`` and ``x0 + 2 * x1 = 8``:\n",
      "        \n",
      "        >>> a = np.array([[3,1], [1,2]])\n",
      "        >>> b = np.array([9,8])\n",
      "        >>> x = np.linalg.solve(a, b)\n",
      "        >>> x\n",
      "        array([2.,  3.])\n",
      "        \n",
      "        Check that the solution is correct:\n",
      "        \n",
      "        >>> np.allclose(np.dot(a, x), b)\n",
      "        True\n",
      "    \n",
      "    svd(a, full_matrices=True, compute_uv=True, hermitian=False)\n",
      "        Singular Value Decomposition.\n",
      "        \n",
      "        When `a` is a 2D array, it is factorized as ``u @ np.diag(s) @ vh\n",
      "        = (u * s) @ vh``, where `u` and `vh` are 2D unitary arrays and `s` is a 1D\n",
      "        array of `a`'s singular values. When `a` is higher-dimensional, SVD is\n",
      "        applied in stacked mode as explained below.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, N) array_like\n",
      "            A real or complex array with ``a.ndim >= 2``.\n",
      "        full_matrices : bool, optional\n",
      "            If True (default), `u` and `vh` have the shapes ``(..., M, M)`` and\n",
      "            ``(..., N, N)``, respectively.  Otherwise, the shapes are\n",
      "            ``(..., M, K)`` and ``(..., K, N)``, respectively, where\n",
      "            ``K = min(M, N)``.\n",
      "        compute_uv : bool, optional\n",
      "            Whether or not to compute `u` and `vh` in addition to `s`.  True\n",
      "            by default.\n",
      "        hermitian : bool, optional\n",
      "            If True, `a` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        u : { (..., M, M), (..., M, K) } array\n",
      "            Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`. The size of the last two dimensions\n",
      "            depends on the value of `full_matrices`. Only returned when\n",
      "            `compute_uv` is True.\n",
      "        s : (..., K) array\n",
      "            Vector(s) with the singular values, within each vector sorted in\n",
      "            descending order. The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`.\n",
      "        vh : { (..., N, N), (..., K, N) } array\n",
      "            Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`. The size of the last two dimensions\n",
      "            depends on the value of `full_matrices`. Only returned when\n",
      "            `compute_uv` is True.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If SVD computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.svd : Similar function in SciPy.\n",
      "        scipy.linalg.svdvals : Compute singular values of a matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionchanged:: 1.8.0\n",
      "           Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "           details.\n",
      "        \n",
      "        The decomposition is performed using LAPACK routine ``_gesdd``.\n",
      "        \n",
      "        SVD is usually described for the factorization of a 2D matrix :math:`A`.\n",
      "        The higher-dimensional case will be discussed below. In the 2D case, SVD is\n",
      "        written as :math:`A = U S V^H`, where :math:`A = a`, :math:`U= u`,\n",
      "        :math:`S= \\mathtt{np.diag}(s)` and :math:`V^H = vh`. The 1D array `s`\n",
      "        contains the singular values of `a` and `u` and `vh` are unitary. The rows\n",
      "        of `vh` are the eigenvectors of :math:`A^H A` and the columns of `u` are\n",
      "        the eigenvectors of :math:`A A^H`. In both cases the corresponding\n",
      "        (possibly non-zero) eigenvalues are given by ``s**2``.\n",
      "        \n",
      "        If `a` has more than two dimensions, then broadcasting rules apply, as\n",
      "        explained in :ref:`routines.linalg-broadcasting`. This means that SVD is\n",
      "        working in \"stacked\" mode: it iterates over all indices of the first\n",
      "        ``a.ndim - 2`` dimensions and for each combination SVD is applied to the\n",
      "        last two indices. The matrix `a` can be reconstructed from the\n",
      "        decomposition with either ``(u * s[..., None, :]) @ vh`` or\n",
      "        ``u @ (s[..., None] * vh)``. (The ``@`` operator can be replaced by the\n",
      "        function ``np.matmul`` for python versions below 3.5.)\n",
      "        \n",
      "        If `a` is a ``matrix`` object (as opposed to an ``ndarray``), then so are\n",
      "        all the return values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.random.randn(9, 6) + 1j*np.random.randn(9, 6)\n",
      "        >>> b = np.random.randn(2, 7, 8, 3) + 1j*np.random.randn(2, 7, 8, 3)\n",
      "        \n",
      "        Reconstruction based on full SVD, 2D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(a, full_matrices=True)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((9, 9), (6,), (6, 6))\n",
      "        >>> np.allclose(a, np.dot(u[:, :6] * s, vh))\n",
      "        True\n",
      "        >>> smat = np.zeros((9, 6), dtype=complex)\n",
      "        >>> smat[:6, :6] = np.diag(s)\n",
      "        >>> np.allclose(a, np.dot(u, np.dot(smat, vh)))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on reduced SVD, 2D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(a, full_matrices=False)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((9, 6), (6,), (6, 6))\n",
      "        >>> np.allclose(a, np.dot(u * s, vh))\n",
      "        True\n",
      "        >>> smat = np.diag(s)\n",
      "        >>> np.allclose(a, np.dot(u, np.dot(smat, vh)))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on full SVD, 4D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(b, full_matrices=True)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((2, 7, 8, 8), (2, 7, 3), (2, 7, 3, 3))\n",
      "        >>> np.allclose(b, np.matmul(u[..., :3] * s[..., None, :], vh))\n",
      "        True\n",
      "        >>> np.allclose(b, np.matmul(u[..., :3], s[..., None] * vh))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on reduced SVD, 4D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(b, full_matrices=False)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((2, 7, 8, 3), (2, 7, 3), (2, 7, 3, 3))\n",
      "        >>> np.allclose(b, np.matmul(u * s[..., None, :], vh))\n",
      "        True\n",
      "        >>> np.allclose(b, np.matmul(u, s[..., None] * vh))\n",
      "        True\n",
      "    \n",
      "    tensorinv(a, ind=2)\n",
      "        Compute the 'inverse' of an N-dimensional array.\n",
      "        \n",
      "        The result is an inverse for `a` relative to the tensordot operation\n",
      "        ``tensordot(a, b, ind)``, i. e., up to floating-point accuracy,\n",
      "        ``tensordot(tensorinv(a), a, ind)`` is the \"identity\" tensor for the\n",
      "        tensordot operation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Tensor to 'invert'. Its shape must be 'square', i. e.,\n",
      "            ``prod(a.shape[:ind]) == prod(a.shape[ind:])``.\n",
      "        ind : int, optional\n",
      "            Number of first indices that are involved in the inverse sum.\n",
      "            Must be a positive integer, default is 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        b : ndarray\n",
      "            `a`'s tensordot inverse, shape ``a.shape[ind:] + a.shape[:ind]``.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not 'square' (in the above sense).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.tensordot, tensorsolve\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.eye(4*6)\n",
      "        >>> a.shape = (4, 6, 8, 3)\n",
      "        >>> ainv = np.linalg.tensorinv(a, ind=2)\n",
      "        >>> ainv.shape\n",
      "        (8, 3, 4, 6)\n",
      "        >>> b = np.random.randn(4, 6)\n",
      "        >>> np.allclose(np.tensordot(ainv, b), np.linalg.tensorsolve(a, b))\n",
      "        True\n",
      "        \n",
      "        >>> a = np.eye(4*6)\n",
      "        >>> a.shape = (24, 8, 3)\n",
      "        >>> ainv = np.linalg.tensorinv(a, ind=1)\n",
      "        >>> ainv.shape\n",
      "        (8, 3, 24)\n",
      "        >>> b = np.random.randn(24)\n",
      "        >>> np.allclose(np.tensordot(ainv, b, 1), np.linalg.tensorsolve(a, b))\n",
      "        True\n",
      "    \n",
      "    tensorsolve(a, b, axes=None)\n",
      "        Solve the tensor equation ``a x = b`` for x.\n",
      "        \n",
      "        It is assumed that all indices of `x` are summed over in the product,\n",
      "        together with the rightmost indices of `a`, as is done in, for example,\n",
      "        ``tensordot(a, x, axes=b.ndim)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Coefficient tensor, of shape ``b.shape + Q``. `Q`, a tuple, equals\n",
      "            the shape of that sub-tensor of `a` consisting of the appropriate\n",
      "            number of its rightmost indices, and must be such that\n",
      "            ``prod(Q) == prod(b.shape)`` (in which sense `a` is said to be\n",
      "            'square').\n",
      "        b : array_like\n",
      "            Right-hand tensor, which can be of any shape.\n",
      "        axes : tuple of ints, optional\n",
      "            Axes in `a` to reorder to the right, before inversion.\n",
      "            If None (default), no reordering is done.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray, shape Q\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not 'square' (in the above sense).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.tensordot, tensorinv, numpy.einsum\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.eye(2*3*4)\n",
      "        >>> a.shape = (2*3, 4, 2, 3, 4)\n",
      "        >>> b = np.random.randn(2*3, 4)\n",
      "        >>> x = np.linalg.tensorsolve(a, b)\n",
      "        >>> x.shape\n",
      "        (2, 3, 4)\n",
      "        >>> np.allclose(np.tensordot(a, x, axes=3), b)\n",
      "        True\n",
      "\n",
      "DATA\n",
      "    test = <numpy._pytesttester.PytestTester object>\n",
      "\n",
      "FILE\n",
      "    /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages/numpy/linalg/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.linalg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function shape in module numpy:\n",
      "\n",
      "shape(a)\n",
      "    Return the shape of an array.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    shape : tuple of ints\n",
      "        The elements of the shape tuple give the lengths of the\n",
      "        corresponding array dimensions.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    alen\n",
      "    ndarray.shape : Equivalent array method.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.shape(np.eye(3))\n",
      "    (3, 3)\n",
      "    >>> np.shape([[1, 2]])\n",
      "    (1, 2)\n",
      "    >>> np.shape([0])\n",
      "    (1,)\n",
      "    >>> np.shape(0)\n",
      "    ()\n",
      "    \n",
      "    >>> a = np.array([(1, 2), (3, 4)], dtype=[('x', 'i4'), ('y', 'i4')])\n",
      "    >>> np.shape(a)\n",
      "    (2,)\n",
      "    >>> a.shape\n",
      "    (2,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(15)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on getset descriptor numpy.ndarray.shape:\n",
      "\n",
      "shape\n",
      "    Tuple of array dimensions.\n",
      "    \n",
      "    The shape property is usually used to get the current shape of an array,\n",
      "    but may also be used to reshape the array in-place by assigning a tuple of\n",
      "    array dimensions to it.  As with `numpy.reshape`, one of the new shape\n",
      "    dimensions can be -1, in which case its value is inferred from the size of\n",
      "    the array and the remaining dimensions. Reshaping an array in-place will\n",
      "    fail if a copy is required.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([1, 2, 3, 4])\n",
      "    >>> x.shape\n",
      "    (4,)\n",
      "    >>> y = np.zeros((2, 3, 4))\n",
      "    >>> y.shape\n",
      "    (2, 3, 4)\n",
      "    >>> y.shape = (3, 8)\n",
      "    >>> y\n",
      "    array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "    >>> y.shape = (3, 6)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<stdin>\", line 1, in <module>\n",
      "    ValueError: total size of new array must be unchanged\n",
      "    >>> np.zeros((4,2))[::2].shape = (-1,)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<stdin>\", line 1, in <module>\n",
      "    AttributeError: Incompatible shape for in-place modification. Use\n",
      "    `.reshape()` to make a copy with the desired shape.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.reshape : similar function\n",
      "    ndarray.reshape : similar method\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.ndarray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "reshape(...)\n",
      "    a.reshape(shape, order='C')\n",
      "    \n",
      "    Returns an array containing the same data with a new shape.\n",
      "    \n",
      "    Refer to `numpy.reshape` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.reshape : equivalent function\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      "    the elements of the shape parameter to be passed in as separate arguments.\n",
      "    For example, ``a.reshape(10, 11)`` is equivalent to\n",
      "    ``a.reshape((10, 11))``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.ndarray.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function reshape:\n",
      "\n",
      "reshape(...) method of numpy.ndarray instance\n",
      "    a.reshape(shape, order='C')\n",
      "    \n",
      "    Returns an array containing the same data with a new shape.\n",
      "    \n",
      "    Refer to `numpy.reshape` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.reshape : equivalent function\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n",
      "    the elements of the shape parameter to be passed in as separate arguments.\n",
      "    For example, ``a.reshape(10, 11)`` is equivalent to\n",
      "    ``a.reshape((10, 11))``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reshape in module numpy:\n",
      "\n",
      "reshape(a, newshape, order='C')\n",
      "    Gives a new shape to an array without changing its data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be reshaped.\n",
      "    newshape : int or tuple of ints\n",
      "        The new shape should be compatible with the original shape. If\n",
      "        an integer, then the result will be a 1-D array of that length.\n",
      "        One shape dimension can be -1. In this case, the value is\n",
      "        inferred from the length of the array and remaining dimensions.\n",
      "    order : {'C', 'F', 'A'}, optional\n",
      "        Read the elements of `a` using this index order, and place the\n",
      "        elements into the reshaped array using this index order.  'C'\n",
      "        means to read / write the elements using C-like index order,\n",
      "        with the last axis index changing fastest, back to the first\n",
      "        axis index changing slowest. 'F' means to read / write the\n",
      "        elements using Fortran-like index order, with the first index\n",
      "        changing fastest, and the last index changing slowest. Note that\n",
      "        the 'C' and 'F' options take no account of the memory layout of\n",
      "        the underlying array, and only refer to the order of indexing.\n",
      "        'A' means to read / write the elements in Fortran-like index\n",
      "        order if `a` is Fortran *contiguous* in memory, C-like order\n",
      "        otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    reshaped_array : ndarray\n",
      "        This will be a new view object if possible; otherwise, it will\n",
      "        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n",
      "        Fortran- contiguous) of the returned array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.reshape : Equivalent method.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    It is not always possible to change the shape of an array without\n",
      "    copying the data. If you want an error to be raised when the data is copied,\n",
      "    you should assign the new shape to the shape attribute of the array::\n",
      "    \n",
      "     >>> a = np.zeros((10, 2))\n",
      "    \n",
      "     # A transpose makes the array non-contiguous\n",
      "     >>> b = a.T\n",
      "    \n",
      "     # Taking a view makes it possible to modify the shape without modifying\n",
      "     # the initial object.\n",
      "     >>> c = b.view()\n",
      "     >>> c.shape = (20)\n",
      "     Traceback (most recent call last):\n",
      "        ...\n",
      "     AttributeError: Incompatible shape for in-place modification. Use\n",
      "     `.reshape()` to make a copy with the desired shape.\n",
      "    \n",
      "    The `order` keyword gives the index ordering both for *fetching* the values\n",
      "    from `a`, and then *placing* the values into the output array.\n",
      "    For example, let's say you have an array:\n",
      "    \n",
      "    >>> a = np.arange(6).reshape((3, 2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "    \n",
      "    You can think of reshaping as first raveling the array (using the given\n",
      "    index order), then inserting the elements from the raveled array into the\n",
      "    new array using the same kind of index ordering as was used for the\n",
      "    raveling.\n",
      "    \n",
      "    >>> np.reshape(a, (2, 3)) # C-like index ordering\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> np.reshape(a, 6)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "    >>> np.reshape(a, 6, order='F')\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "    \n",
      "    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10],\n",
       "       [ 1,  6, 11],\n",
       "       [ 2,  7, 12],\n",
       "       [ 3,  8, 13],\n",
       "       [ 4,  9, 14]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((5,3),order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arreglos\n",
    "\n",
    "![Image](https://www.pythoninformer.com/img/numpy/2d-array.png) ![Image](https://www.pythoninformer.com/img/numpy/3d-array-stack.png) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1. ,  5.5, 10. ])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.linspace(1,10,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "(15,)\n",
      "[[ 1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10.]\n",
      " [11. 12. 13. 14. 15.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.linspace(1,15,15)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "b = b.reshape((3,5))\n",
    "print(b)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]\n",
      "(30,)\n",
      "[[[ 1.  2.  3.  4.  5.]\n",
      "  [ 6.  7.  8.  9. 10.]\n",
      "  [11. 12. 13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18. 19. 20.]\n",
      "  [21. 22. 23. 24. 25.]\n",
      "  [26. 27. 28. 29. 30.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.linspace(1,30,30)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "c = c.reshape((2,3,5))\n",
    "print(c)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.ones((2,3,5))\n",
    "print(d.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.geeksforgeeks.org/wp-content/uploads/Numpy1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10.],\n",
       "        [11., 12., 13., 14., 15.]],\n",
       "\n",
       "       [[16., 17., 18., 19., 20.],\n",
       "        [21., 22., 23., 24., 25.],\n",
       "        [26., 27., 28., 29., 30.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[5., 6.],\n",
       "        [7., 8.]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.linspace(1,8,8)\n",
    "e.reshape((2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.],\n",
       "        [3., 4.]],\n",
       "\n",
       "       [[5., 6.],\n",
       "        [7., 8.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.array([[[1., 2.],[3., 4.]],[[5., 6.],[7., 8.]]])\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 12.],\n",
       "       [21., 32.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0,:,:]*e[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 22.],\n",
       "       [43., 50.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0,:,:]@e[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 22.],\n",
       "       [43., 50.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0,:,:].dot(e[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function multi_dot in module numpy.linalg:\n",
      "\n",
      "multi_dot(arrays, *, out=None)\n",
      "    Compute the dot product of two or more arrays in a single function call,\n",
      "    while automatically selecting the fastest evaluation order.\n",
      "    \n",
      "    `multi_dot` chains `numpy.dot` and uses optimal parenthesization\n",
      "    of the matrices [1]_ [2]_. Depending on the shapes of the matrices,\n",
      "    this can speed up the multiplication a lot.\n",
      "    \n",
      "    If the first argument is 1-D it is treated as a row vector.\n",
      "    If the last argument is 1-D it is treated as a column vector.\n",
      "    The other arguments must be 2-D.\n",
      "    \n",
      "    Think of `multi_dot` as::\n",
      "    \n",
      "        def multi_dot(arrays): return functools.reduce(np.dot, arrays)\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arrays : sequence of array_like\n",
      "        If the first argument is 1-D it is treated as row vector.\n",
      "        If the last argument is 1-D it is treated as column vector.\n",
      "        The other arguments must be 2-D.\n",
      "    out : ndarray, optional\n",
      "        Output argument. This must have the exact kind that would be returned\n",
      "        if it was not used. In particular, it must have the right type, must be\n",
      "        C-contiguous, and its dtype must be the dtype that would be returned\n",
      "        for `dot(a, b)`. This is a performance feature. Therefore, if these\n",
      "        conditions are not met, an exception is raised, instead of attempting\n",
      "        to be flexible.\n",
      "    \n",
      "        .. versionadded:: 1.19.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        Returns the dot product of the supplied arrays.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    dot : dot multiplication with two arguments.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    \n",
      "    .. [1] Cormen, \"Introduction to Algorithms\", Chapter 15.2, p. 370-378\n",
      "    .. [2] https://en.wikipedia.org/wiki/Matrix_chain_multiplication\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    `multi_dot` allows you to write::\n",
      "    \n",
      "    >>> from numpy.linalg import multi_dot\n",
      "    >>> # Prepare some data\n",
      "    >>> A = np.random.random((10000, 100))\n",
      "    >>> B = np.random.random((100, 1000))\n",
      "    >>> C = np.random.random((1000, 5))\n",
      "    >>> D = np.random.random((5, 333))\n",
      "    >>> # the actual dot multiplication\n",
      "    >>> _ = multi_dot([A, B, C, D])\n",
      "    \n",
      "    instead of::\n",
      "    \n",
      "    >>> _ = np.dot(np.dot(np.dot(A, B), C), D)\n",
      "    >>> # or\n",
      "    >>> _ = A.dot(B).dot(C).dot(D)\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The cost for a matrix multiplication can be calculated with the\n",
      "    following function::\n",
      "    \n",
      "        def cost(A, B):\n",
      "            return A.shape[0] * A.shape[1] * B.shape[1]\n",
      "    \n",
      "    Assume we have three matrices\n",
      "    :math:`A_{10x100}, B_{100x5}, C_{5x50}`.\n",
      "    \n",
      "    The costs for the two different parenthesizations are as follows::\n",
      "    \n",
      "        cost((AB)C) = 10*100*5 + 10*5*50   = 5000 + 2500   = 7500\n",
      "        cost(A(BC)) = 10*100*50 + 100*5*50 = 50000 + 25000 = 75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.linalg.multi_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 22.],\n",
       "       [43., 50.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.multi_dot([e[0,:,:],e[1,:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   5.5 10. ]\n",
      "[[ 1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10.]\n",
      " [11. 12. 13. 14. 15.]]\n",
      "[144.  160.5 177.  193.5 210. ]\n",
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)\n",
    "print(c[0,:,:])\n",
    "r = a.dot(c[0,:,:])\n",
    "print(r)\n",
    "print(r.shape)\n",
    "r.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   5.5 10. ]]\n",
      "[[144.  160.5 177.  193.5 210. ]]\n",
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = a.reshape((1,3))\n",
    "print(ap)\n",
    "ap.shape\n",
    "rp = ap.dot(c[0,:,:])\n",
    "print(rp)\n",
    "print(rp.shape)\n",
    "rp.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   5.5 10. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = a.T\n",
    "print(at)\n",
    "at.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. ]\n",
      " [ 5.5]\n",
      " [10. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt = ap.T\n",
    "print(apt)\n",
    "apt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   5.5 10. ]\n",
      "[16.5 16.5 16.5]\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(at)\n",
    "r = np.ones((3,3)).dot(at)\n",
    "print(r)\n",
    "print(r.shape)\n",
    "r.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. ]\n",
      " [ 5.5]\n",
      " [10. ]]\n",
      "[[16.5]\n",
      " [16.5]\n",
      " [16.5]]\n",
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(apt)\n",
    "r = np.ones((3,3)).dot(apt)\n",
    "print(r)\n",
    "print(r.shape)\n",
    "r.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo Econometría\n",
    "\n",
    "\n",
    "Los datos del libro de Wooldridge se encuentran en la siguiente direccción [enlace](https://github.com/spring-haru/wooldridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wooldridge\n",
      "  Downloading wooldridge-0.4.2-py3-none-any.whl (5.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.1 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages (from wooldridge) (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages (from pandas->wooldridge) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages (from pandas->wooldridge) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages (from pandas->wooldridge) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rafamtz/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->wooldridge) (1.15.0)\n",
      "Installing collected packages: wooldridge\n",
      "Successfully installed wooldridge-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wooldridge # solo es necesario instalarlo una vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__author__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__copyright__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'abspath',\n",
       " 'data',\n",
       " 'dataWoo',\n",
       " 'get_path',\n",
       " 'join',\n",
       " 'load_data',\n",
       " 'lst',\n",
       " 'pd',\n",
       " 'split']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(woo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tetsu Haruyama'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woo.__author__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Python documentation found for 'J.M. Wooldridge (2016) Introductory Econometrics: A Modern Approach,\\n  Cengage Learning, 6th edition.\\n\\n  401k       401ksubs    admnrev       affairs     airfare\\n  alcohol    apple       approval      athlet1     athlet2\\n  attend     audit       barium        beauty      benefits\\n  beveridge  big9salary  bwght         bwght2      campus\\n  card       catholic    cement        census2000  ceosal1\\n  ceosal2    charity     consump       corn        countymurders\\n  cps78_85   cps91       crime1        crime2      crime3\\n  crime4     discrim     driving       earns       econmath\\n  elem94_95  engin       expendshares  ezanders    ezunem\\n  fair       fertil1     fertil2       fertil3     fish\\n  fringe     gpa1        gpa2          gpa3        happiness\\n  hprice1    hprice2     hprice3       hseinv      htv\\n  infmrt     injury      intdef        intqrt      inven\\n  jtrain     jtrain2     jtrain3       kielmc      lawsch85\\n  loanapp    lowbrth     mathpnl       meap00_01   meap01\\n  meap93     meapsingle  minwage       mlb1        mroz\\n  murder     nbasal      nyse          okun        openness\\n  pension    phillips    pntsprd       prison      prminwge\\n  rdchem     rdtelec     recid         rental      return\\n  saving     sleep75     slp75_81      smoke       traffic1\\n  traffic2   twoyear     volat         vote1       vote2\\n  voucher    wage1       wage2         wagepan     wageprc\\n  wine'.\n",
      "Use help() to get the interactive help utility.\n",
      "Use help(str) for help on the str class.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(woo.lst) # lista de conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Simple \n",
    "\n",
    "\n",
    "$$y = \\beta_0 +\\beta_1 x + u$$\n",
    "\n",
    "$$\\hat\\beta_0 = \\bar{y}-\\hat\\beta_1 \\bar{x}$$\n",
    "$$\\hat\\beta_1= \\frac{Cov(x,y)}{Var(x)}$$\n",
    "\n",
    "### Wooldridge 2016, ejemplo-2-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>pcsalary</th>\n",
       "      <th>sales</th>\n",
       "      <th>roe</th>\n",
       "      <th>pcroe</th>\n",
       "      <th>ros</th>\n",
       "      <th>indus</th>\n",
       "      <th>finance</th>\n",
       "      <th>consprod</th>\n",
       "      <th>utility</th>\n",
       "      <th>lsalary</th>\n",
       "      <th>lsales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1095</td>\n",
       "      <td>20</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>14.1</td>\n",
       "      <td>106.400002</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.998509</td>\n",
       "      <td>10.225389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>32</td>\n",
       "      <td>9958.000000</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-30.600000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>9.206132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1122</td>\n",
       "      <td>9</td>\n",
       "      <td>6125.899902</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-16.299999</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.022868</td>\n",
       "      <td>8.720281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>-9</td>\n",
       "      <td>16246.000000</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-25.700001</td>\n",
       "      <td>-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.359574</td>\n",
       "      <td>9.695602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1368</td>\n",
       "      <td>7</td>\n",
       "      <td>21783.199219</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.221105</td>\n",
       "      <td>9.988894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>930</td>\n",
       "      <td>10</td>\n",
       "      <td>1509.099976</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.835185</td>\n",
       "      <td>7.319269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>525</td>\n",
       "      <td>3</td>\n",
       "      <td>1097.099976</td>\n",
       "      <td>15.5</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.263398</td>\n",
       "      <td>7.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>658</td>\n",
       "      <td>32</td>\n",
       "      <td>4542.600098</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-7.800000</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.489205</td>\n",
       "      <td>8.421255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>555</td>\n",
       "      <td>6</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-14.600000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.318968</td>\n",
       "      <td>7.612337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>1442.500000</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-10.200000</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.439351</td>\n",
       "      <td>7.274133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     salary  pcsalary         sales   roe       pcroe  ros  indus  finance  \\\n",
       "0      1095        20  27595.000000  14.1  106.400002  191      1        0   \n",
       "1      1001        32   9958.000000  10.9  -30.600000   13      1        0   \n",
       "2      1122         9   6125.899902  23.5  -16.299999   14      1        0   \n",
       "3       578        -9  16246.000000   5.9  -25.700001  -21      1        0   \n",
       "4      1368         7  21783.199219  13.8   -3.000000   56      1        0   \n",
       "..      ...       ...           ...   ...         ...  ...    ...      ...   \n",
       "204     930        10   1509.099976   9.0   20.500000  131      0        0   \n",
       "205     525         3   1097.099976  15.5   20.100000   72      0        0   \n",
       "206     658        32   4542.600098  12.1   -7.800000   68      0        0   \n",
       "207     555         6   2023.000000  13.7  -14.600000   60      0        0   \n",
       "208     626         0   1442.500000  14.4  -10.200000   62      0        0   \n",
       "\n",
       "     consprod  utility   lsalary     lsales  \n",
       "0           0        0  6.998509  10.225389  \n",
       "1           0        0  6.908755   9.206132  \n",
       "2           0        0  7.022868   8.720281  \n",
       "3           0        0  6.359574   9.695602  \n",
       "4           0        0  7.221105   9.988894  \n",
       "..        ...      ...       ...        ...  \n",
       "204         0        1  6.835185   7.319269  \n",
       "205         0        1  6.263398   7.000426  \n",
       "206         0        1  6.489205   8.421255  \n",
       "207         0        1  6.318968   7.612337  \n",
       "208         0        1  6.439351   7.274133  \n",
       "\n",
       "[209 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceosal1 = woo.data('ceosal1')\n",
    "ceosal1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "x = ceosal1['roe']\n",
    "y = ceosal1['salary']\n",
    "print(type(x),type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.25649898e+01 1.34253840e+03]\n",
      " [1.34253840e+03 1.88333164e+06]]\n"
     ]
    }
   ],
   "source": [
    "cov = np.cov(x,y)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1342.5383979609712"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_xy = cov[0,1]\n",
    "cov_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.21778886672104"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_x = np.var(x)\n",
    "var_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.18421050521175 1281.1196172248804\n"
     ]
    }
   ],
   "source": [
    "x_bar = np.mean(x)\n",
    "y_bar = np.mean(y)\n",
    "print(x_bar,y_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963.1913364725579 18.501186345214922\n"
     ]
    }
   ],
   "source": [
    "var_x= np.var(x,ddof = 1) # utilizamos la varianza correcta\n",
    "b1 = cov_xy/var_x\n",
    "b0 = y_bar - b1  * x_bar\n",
    "print(b0,b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function var in module numpy:\n",
      "\n",
      "var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>)\n",
      "    Compute the variance along the specified axis.\n",
      "    \n",
      "    Returns the variance of the array elements, a measure of the spread of a\n",
      "    distribution.  The variance is computed for the flattened array by\n",
      "    default, otherwise over the specified axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array containing numbers whose variance is desired.  If `a` is not an\n",
      "        array, a conversion is attempted.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which the variance is computed.  The default is to\n",
      "        compute the variance of the flattened array.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If this is a tuple of ints, a variance is performed over multiple axes,\n",
      "        instead of a single axis or all the axes as before.\n",
      "    dtype : data-type, optional\n",
      "        Type to use in computing the variance.  For arrays of integer type\n",
      "        the default is `float64`; for arrays of float types it is the same as\n",
      "        the array type.\n",
      "    out : ndarray, optional\n",
      "        Alternate output array in which to place the result.  It must have\n",
      "        the same shape as the expected output, but the type is cast if\n",
      "        necessary.\n",
      "    ddof : int, optional\n",
      "        \"Delta Degrees of Freedom\": the divisor used in the calculation is\n",
      "        ``N - ddof``, where ``N`` represents the number of elements. By\n",
      "        default `ddof` is zero.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `var` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    variance : ndarray, see dtype parameter above\n",
      "        If ``out=None``, returns a new array containing the variance;\n",
      "        otherwise, a reference to the output array is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    std, mean, nanmean, nanstd, nanvar\n",
      "    ufuncs-output-type\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The variance is the average of the squared deviations from the mean,\n",
      "    i.e.,  ``var = mean(abs(x - x.mean())**2)``.\n",
      "    \n",
      "    The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.\n",
      "    If, however, `ddof` is specified, the divisor ``N - ddof`` is used\n",
      "    instead.  In standard statistical practice, ``ddof=1`` provides an\n",
      "    unbiased estimator of the variance of a hypothetical infinite population.\n",
      "    ``ddof=0`` provides a maximum likelihood estimate of the variance for\n",
      "    normally distributed variables.\n",
      "    \n",
      "    Note that for complex numbers, the absolute value is taken before\n",
      "    squaring, so that the result is always real and nonnegative.\n",
      "    \n",
      "    For floating-point input, the variance is computed using the same\n",
      "    precision the input has.  Depending on the input data, this can cause\n",
      "    the results to be inaccurate, especially for `float32` (see example\n",
      "    below).  Specifying a higher-accuracy accumulator using the ``dtype``\n",
      "    keyword can alleviate this issue.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> np.var(a)\n",
      "    1.25\n",
      "    >>> np.var(a, axis=0)\n",
      "    array([1.,  1.])\n",
      "    >>> np.var(a, axis=1)\n",
      "    array([0.25,  0.25])\n",
      "    \n",
      "    In single precision, var() can be inaccurate:\n",
      "    \n",
      "    >>> a = np.zeros((2, 512*512), dtype=np.float32)\n",
      "    >>> a[0, :] = 1.0\n",
      "    >>> a[1, :] = 0.1\n",
      "    >>> np.var(a)\n",
      "    0.20250003\n",
      "    \n",
      "    Computing the variance in float64 is more accurate:\n",
      "    \n",
      "    >>> np.var(a, dtype=np.float64)\n",
      "    0.20249999932944759 # may vary\n",
      "    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2\n",
      "    0.2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Módulo statsmodels\n",
    "\n",
    "[statsmodels](https://www.statsmodels.org/stable/index.html) _es un módulo de Python que proporciona clases y funciones para la estimación de muchos modelos estadísticos diferentes, así como para realizar pruebas estadísticas y exploración de datos estadísticos. Hay disponible una lista extensa de estadísticas de resultados para cada estimador._\n",
    "\n",
    "**Tarea moral: instalar statsmodels con conda**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf # submodulo que permite utilizar las sintaxis de R para regresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_smf = smf.ols(formula = 'salary ~ roe',\n",
    "              data = ceosal1\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lo anterior solo es configuración del estimador, esto es común en algunos módulos de Python, por ejemplo el módulo [scikit-learn](https://scikit-learn.org/stable/) para Machine Learning, tiene esta misma idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.OLS"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reg_smf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_data_attr',\n",
       " '_df_model',\n",
       " '_df_resid',\n",
       " '_fit_collinear',\n",
       " '_fit_ridge',\n",
       " '_fit_zeros',\n",
       " '_formula_max_endog',\n",
       " '_get_init_kwds',\n",
       " '_handle_data',\n",
       " '_init_keys',\n",
       " '_setup_score_hess',\n",
       " '_sqrt_lasso',\n",
       " 'data',\n",
       " 'df_model',\n",
       " 'df_resid',\n",
       " 'endog',\n",
       " 'endog_names',\n",
       " 'exog',\n",
       " 'exog_names',\n",
       " 'fit',\n",
       " 'fit_regularized',\n",
       " 'formula',\n",
       " 'from_formula',\n",
       " 'get_distribution',\n",
       " 'hessian',\n",
       " 'hessian_factor',\n",
       " 'information',\n",
       " 'initialize',\n",
       " 'k_constant',\n",
       " 'loglike',\n",
       " 'nobs',\n",
       " 'predict',\n",
       " 'rank',\n",
       " 'score',\n",
       " 'weights',\n",
       " 'wendog',\n",
       " 'wexog',\n",
       " 'whiten']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(reg_smf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OLS in module statsmodels.regression.linear_model object:\n",
      "\n",
      "class OLS(WLS)\n",
      " |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |  \n",
      " |  Ordinary Least Squares\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  **kwargs\n",
      " |      Extra arguments that are used to set model properties when using the\n",
      " |      formula interface.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : scalar\n",
      " |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  WLS : Fit a linear model using Weighted Least Squares.\n",
      " |  GLS : Fit a linear model using Generalized Least Squares.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  No constant is added by the model unless you are using formulas.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> import numpy as np\n",
      " |  >>> duncan_prestige = sm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
      " |  >>> Y = duncan_prestige.data['income']\n",
      " |  >>> X = duncan_prestige.data['education']\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>> model = sm.OLS(Y,X)\n",
      " |  >>> results = model.fit()\n",
      " |  >>> results.params\n",
      " |  const        10.603498\n",
      " |  education     0.594859\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> results.tvalues\n",
      " |  const        2.039813\n",
      " |  education    6.892802\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |                               Test for Constraints\n",
      " |  ==============================================================================\n",
      " |                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |  ------------------------------------------------------------------------------\n",
      " |  c0            10.6035      5.198      2.040      0.048       0.120      21.087\n",
      " |  ==============================================================================\n",
      " |  \n",
      " |  >>> print(results.f_test(np.identity(2)))\n",
      " |  <F test: F=array([[159.63031026]]), p=1.2607168903696672e-20, df_denom=43, df_num=2>\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OLS\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str\n",
      " |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      " |      alpha : scalar or array_like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt : scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array_like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.base.elastic_net.RegularizedResults\n",
      " |          The regularized results.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |      \n",
      " |      The function that is minimized is:\n",
      " |      \n",
      " |      .. math::\n",
      " |      \n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |      \n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |      \n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |      \n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |      \n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |      \n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |      \n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |      \n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |      \n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |      \n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The cvxopt module is required to estimate model using the square root\n",
      " |      lasso.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |         generalized linear models via coordinate descent.  Journal of\n",
      " |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |      \n",
      " |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |         pivotal recovery of sparse signals via conic programming.\n",
      " |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      " |  \n",
      " |  hessian(self, params, scale=None)\n",
      " |      Evaluate the Hessian function at a given point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the Hessian is computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The Hessian matrix.\n",
      " |  \n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Calculate the weights for the Hessian.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameter at which Hessian is evaluated.\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      " |  \n",
      " |  loglike(self, params, scale=None)\n",
      " |      The likelihood function for the OLS model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The coefficients with which to estimate the log-likelihood.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The likelihood function evaluated at params.\n",
      " |  \n",
      " |  score(self, params, scale=None)\n",
      " |      Evaluate the score function at a given point.\n",
      " |      \n",
      " |      The score corresponds to the profile (concentrated)\n",
      " |      log-likelihood in which the scale parameter has been profiled\n",
      " |      out.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the score function is\n",
      " |          computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector.\n",
      " |  \n",
      " |  whiten(self, x)\n",
      " |      OLS model whitener does nothing.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Data to be whitened.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          The input array unmodified.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      OLS : Fit a linear model using Ordinary Least Squares.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |  \n",
      " |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |      \n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators.\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance\n",
      " |          estimators.\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      RegressionResults\n",
      " |          The model estimation results.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      RegressionResults\n",
      " |          The results container.\n",
      " |      RegressionResults.get_robustcov_results\n",
      " |          A method to change the covariance estimator used when fitting the\n",
      " |          model.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |  \n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Construct a random number generator for the predictive distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array_like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize model components.\n",
      " |  \n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model.\n",
      " |      exog : array_like, optional\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          An array of fitted values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |  \n",
      " |  df_model\n",
      " |      The model degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      " |      constant is included.\n",
      " |  \n",
      " |  df_resid\n",
      " |      The residual degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the number of observations minus the rank of\n",
      " |      the regressor matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |      \n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(reg_smf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RegressionResultsWrapper in module statsmodels.regression.linear_model object:\n",
      "\n",
      "class RegressionResultsWrapper(statsmodels.base.wrapper.ResultsWrapper)\n",
      " |  RegressionResultsWrapper(results)\n",
      " |  \n",
      " |  Class which wraps a statsmodels estimation Results class and steps in to\n",
      " |  reattach metadata to results (if available)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RegressionResultsWrapper\n",
      " |      statsmodels.base.wrapper.ResultsWrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  conf_int(self, alpha=0.05, cols=None)\n",
      " |      conf_int(self, alpha=0.05, cols=None)\n",
      " |      \n",
      " |      Compute the confidence interval of the fitted parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : float, optional\n",
      " |          The `alpha` level for the confidence interval. The default\n",
      " |          `alpha` = .05 returns a 95% confidence interval.\n",
      " |      cols : array_like, optional\n",
      " |          Columns to included in returned confidence intervals.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          The confidence intervals.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The confidence interval is based on Student's t-distribution.\n",
      " |  \n",
      " |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      " |      cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      " |      \n",
      " |      Compute the variance/covariance matrix.\n",
      " |      \n",
      " |      The variance/covariance matrix can be of a linear contrast of the\n",
      " |      estimated parameters or all params multiplied by scale which will\n",
      " |      usually be an estimate of sigma^2.  Scale is assumed to be a scalar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array_like\n",
      " |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      " |      column : array_like, optional\n",
      " |          Must be used on its own.  Can be 0d or 1d see below.\n",
      " |      scale : float, optional\n",
      " |          Can be specified or not.  Default is None, which means that\n",
      " |          the scale argument is taken from the model.\n",
      " |      cov_p : ndarray, optional\n",
      " |          The covariance of the parameters. If not provided, this value is\n",
      " |          read from `self.normalized_cov_params` or\n",
      " |          `self.cov_params_default`.\n",
      " |      other : array_like, optional\n",
      " |          Can be used when r_matrix is specified.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The covariance matrix of the parameter estimates or of linear\n",
      " |          combination of parameter estimates. See Notes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      (The below are assumed to be in matrix notation.)\n",
      " |      \n",
      " |      If no argument is specified returns the covariance matrix of a model\n",
      " |      ``(scale)*(X.T X)^(-1)``\n",
      " |      \n",
      " |      If contrast is specified it pre and post-multiplies as follows\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      " |      \n",
      " |      If contrast and other are specified returns\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      " |      \n",
      " |      If column is specified returns\n",
      " |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      " |      \n",
      " |      OR\n",
      " |      \n",
      " |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattribute__(self, attr)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __init__(self, results)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setstate__(self, dict_)\n",
      " |  \n",
      " |  save(self, fname, remove_data=False)\n",
      " |      Save a pickle of this instance.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : {str, handle}\n",
      " |          Either a filename or a valid file handle.\n",
      " |      remove_data : bool\n",
      " |          If False (default), then the instance is pickled without changes.\n",
      " |          If True, then all arrays with length nobs are set to None before\n",
      " |          pickling. See the remove_data method.\n",
      " |          In some cases not all arrays will be set to None.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      " |  \n",
      " |  load(fname) from builtins.type\n",
      " |      Load a pickled results instance\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         Loading pickled models is not secure against erroneous or\n",
      " |         maliciously constructed data. Never unpickle data received from\n",
      " |         an untrusted or unauthenticated source.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : {str, handle}\n",
      " |          A string filename or a file handle.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Results\n",
      " |          The unpickled results instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(reg_smf.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HC0_se',\n",
       " 'HC1_se',\n",
       " 'HC2_se',\n",
       " 'HC3_se',\n",
       " '_HCCM',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abat_diagonal',\n",
       " '_cache',\n",
       " '_data_attr',\n",
       " '_data_in_cache',\n",
       " '_get_robustcov_results',\n",
       " '_is_nested',\n",
       " '_use_t',\n",
       " '_wexog_singular_values',\n",
       " 'aic',\n",
       " 'bic',\n",
       " 'bse',\n",
       " 'centered_tss',\n",
       " 'compare_f_test',\n",
       " 'compare_lm_test',\n",
       " 'compare_lr_test',\n",
       " 'condition_number',\n",
       " 'conf_int',\n",
       " 'conf_int_el',\n",
       " 'cov_HC0',\n",
       " 'cov_HC1',\n",
       " 'cov_HC2',\n",
       " 'cov_HC3',\n",
       " 'cov_kwds',\n",
       " 'cov_params',\n",
       " 'cov_type',\n",
       " 'df_model',\n",
       " 'df_resid',\n",
       " 'eigenvals',\n",
       " 'el_test',\n",
       " 'ess',\n",
       " 'f_pvalue',\n",
       " 'f_test',\n",
       " 'fittedvalues',\n",
       " 'fvalue',\n",
       " 'get_influence',\n",
       " 'get_prediction',\n",
       " 'get_robustcov_results',\n",
       " 'initialize',\n",
       " 'k_constant',\n",
       " 'llf',\n",
       " 'load',\n",
       " 'model',\n",
       " 'mse_model',\n",
       " 'mse_resid',\n",
       " 'mse_total',\n",
       " 'nobs',\n",
       " 'normalized_cov_params',\n",
       " 'outlier_test',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'pvalues',\n",
       " 'remove_data',\n",
       " 'resid',\n",
       " 'resid_pearson',\n",
       " 'rsquared',\n",
       " 'rsquared_adj',\n",
       " 'save',\n",
       " 'scale',\n",
       " 'ssr',\n",
       " 'summary',\n",
       " 'summary2',\n",
       " 't_test',\n",
       " 't_test_pairwise',\n",
       " 'tvalues',\n",
       " 'uncentered_tss',\n",
       " 'use_t',\n",
       " 'wald_test',\n",
       " 'wald_test_terms',\n",
       " 'wresid']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(reg_smf.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.RegressionResultsWrapper"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion = reg_smf.fit()\n",
    "type(regresion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    963.191336\n",
       "roe           18.501186\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>salary</td>      <th>  R-squared:         </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0978</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:41:31</td>     <th>  Log-Likelihood:    </th> <td> -1804.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   209</td>      <th>  AIC:               </th> <td>   3613.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   207</td>      <th>  BIC:               </th> <td>   3620.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  963.1913</td> <td>  213.240</td> <td>    4.517</td> <td> 0.000</td> <td>  542.790</td> <td> 1383.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roe</th>       <td>   18.5012</td> <td>   11.123</td> <td>    1.663</td> <td> 0.098</td> <td>   -3.428</td> <td>   40.431</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>311.096</td> <th>  Durbin-Watson:     </th> <td>   2.105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>31120.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.915</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>61.158</td>  <th>  Cond. No.          </th> <td>    43.3</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 salary   R-squared:                       0.013\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     2.767\n",
       "Date:                Thu, 15 Apr 2021   Prob (F-statistic):             0.0978\n",
       "Time:                        13:41:31   Log-Likelihood:                -1804.5\n",
       "No. Observations:                 209   AIC:                             3613.\n",
       "Df Residuals:                     207   BIC:                             3620.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    963.1913    213.240      4.517      0.000     542.790    1383.592\n",
       "roe           18.5012     11.123      1.663      0.098      -3.428      40.431\n",
       "==============================================================================\n",
       "Omnibus:                      311.096   Durbin-Watson:                   2.105\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31120.902\n",
       "Skew:                           6.915   Prob(JB):                         0.00\n",
       "Kurtosis:                      61.158   Cond. No.                         43.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot('roe',\n",
    "        'salary',\n",
    "        data = ceosal1,\n",
    "        color = 'red',\n",
    "        marker = 'o',\n",
    "        linestyle = '')\n",
    "\n",
    "plt.plot(ceosal1['roe'],\n",
    "         regresion.fittedvalues,\n",
    "         color = 'black',\n",
    "         linestyle = '-')\n",
    "\n",
    "plt.ylabel('salary')\n",
    "plt.xlabel('roe')\n",
    "plt.savefig('mireg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm # importamos el submododulo pero este no tiene la sintasix R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BayesGaussMI',\n",
       " 'BinomialBayesMixedGLM',\n",
       " 'Factor',\n",
       " 'GEE',\n",
       " 'GLM',\n",
       " 'GLMGam',\n",
       " 'GLS',\n",
       " 'GLSAR',\n",
       " 'GeneralizedPoisson',\n",
       " 'Logit',\n",
       " 'MANOVA',\n",
       " 'MI',\n",
       " 'MICE',\n",
       " 'MICEData',\n",
       " 'MNLogit',\n",
       " 'MixedLM',\n",
       " 'NegativeBinomial',\n",
       " 'NegativeBinomialP',\n",
       " 'NominalGEE',\n",
       " 'OLS',\n",
       " 'OrdinalGEE',\n",
       " 'PCA',\n",
       " 'PHReg',\n",
       " 'Poisson',\n",
       " 'PoissonBayesMixedGLM',\n",
       " 'ProbPlot',\n",
       " 'Probit',\n",
       " 'QuantReg',\n",
       " 'RLM',\n",
       " 'RecursiveLS',\n",
       " 'SurvfuncRight',\n",
       " 'WLS',\n",
       " 'ZeroInflatedGeneralizedPoisson',\n",
       " 'ZeroInflatedNegativeBinomialP',\n",
       " 'ZeroInflatedPoisson',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'add_constant',\n",
       " 'categorical',\n",
       " 'cov_struct',\n",
       " 'datasets',\n",
       " 'distributions',\n",
       " 'duration',\n",
       " 'emplike',\n",
       " 'families',\n",
       " 'formula',\n",
       " 'gam',\n",
       " 'genmod',\n",
       " 'graphics',\n",
       " 'iolib',\n",
       " 'load',\n",
       " 'load_pickle',\n",
       " 'multivariate',\n",
       " 'nonparametric',\n",
       " 'os',\n",
       " 'qqline',\n",
       " 'qqplot',\n",
       " 'qqplot_2samples',\n",
       " 'regression',\n",
       " 'robust',\n",
       " 'show_versions',\n",
       " 'stats',\n",
       " 'test',\n",
       " 'tools',\n",
       " 'tsa',\n",
       " 'webdoc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class OLS(WLS)\n",
      " |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |  \n",
      " |  Ordinary Least Squares\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  **kwargs\n",
      " |      Extra arguments that are used to set model properties when using the\n",
      " |      formula interface.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : scalar\n",
      " |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  WLS : Fit a linear model using Weighted Least Squares.\n",
      " |  GLS : Fit a linear model using Generalized Least Squares.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  No constant is added by the model unless you are using formulas.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> import numpy as np\n",
      " |  >>> duncan_prestige = sm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
      " |  >>> Y = duncan_prestige.data['income']\n",
      " |  >>> X = duncan_prestige.data['education']\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>> model = sm.OLS(Y,X)\n",
      " |  >>> results = model.fit()\n",
      " |  >>> results.params\n",
      " |  const        10.603498\n",
      " |  education     0.594859\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> results.tvalues\n",
      " |  const        2.039813\n",
      " |  education    6.892802\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |                               Test for Constraints\n",
      " |  ==============================================================================\n",
      " |                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |  ------------------------------------------------------------------------------\n",
      " |  c0            10.6035      5.198      2.040      0.048       0.120      21.087\n",
      " |  ==============================================================================\n",
      " |  \n",
      " |  >>> print(results.f_test(np.identity(2)))\n",
      " |  <F test: F=array([[159.63031026]]), p=1.2607168903696672e-20, df_denom=43, df_num=2>\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OLS\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str\n",
      " |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      " |      alpha : scalar or array_like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt : scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array_like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.base.elastic_net.RegularizedResults\n",
      " |          The regularized results.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |      \n",
      " |      The function that is minimized is:\n",
      " |      \n",
      " |      .. math::\n",
      " |      \n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |      \n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |      \n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |      \n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |      \n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |      \n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |      \n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |      \n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |      \n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |      \n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The cvxopt module is required to estimate model using the square root\n",
      " |      lasso.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |         generalized linear models via coordinate descent.  Journal of\n",
      " |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |      \n",
      " |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |         pivotal recovery of sparse signals via conic programming.\n",
      " |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      " |  \n",
      " |  hessian(self, params, scale=None)\n",
      " |      Evaluate the Hessian function at a given point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the Hessian is computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The Hessian matrix.\n",
      " |  \n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Calculate the weights for the Hessian.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameter at which Hessian is evaluated.\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      " |  \n",
      " |  loglike(self, params, scale=None)\n",
      " |      The likelihood function for the OLS model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The coefficients with which to estimate the log-likelihood.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The likelihood function evaluated at params.\n",
      " |  \n",
      " |  score(self, params, scale=None)\n",
      " |      Evaluate the score function at a given point.\n",
      " |      \n",
      " |      The score corresponds to the profile (concentrated)\n",
      " |      log-likelihood in which the scale parameter has been profiled\n",
      " |      out.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter vector at which the score function is\n",
      " |          computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector.\n",
      " |  \n",
      " |  whiten(self, x)\n",
      " |      OLS model whitener does nothing.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Data to be whitened.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          The input array unmodified.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      OLS : Fit a linear model using Ordinary Least Squares.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |  \n",
      " |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |      \n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators.\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance\n",
      " |          estimators.\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      RegressionResults\n",
      " |          The model estimation results.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      RegressionResults\n",
      " |          The results container.\n",
      " |      RegressionResults.get_robustcov_results\n",
      " |          A method to change the covariance estimator used when fitting the\n",
      " |          model.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |  \n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Construct a random number generator for the predictive distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array_like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize model components.\n",
      " |  \n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model.\n",
      " |      exog : array_like, optional\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          An array of fitted values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |  \n",
      " |  df_model\n",
      " |      The model degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      " |      constant is included.\n",
      " |  \n",
      " |  df_resid\n",
      " |      The residual degree of freedom.\n",
      " |      \n",
      " |      The dof is defined as the number of observations minus the rank of\n",
      " |      the regressor matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |      \n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    963.191336\n",
       "roe       18.501186\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = ceosal1['salary']\n",
    "X = ceosal1['roe']\n",
    "X = sm.add_constant(X)\n",
    "reg_sm = sm.OLS(Y,X)       # configuramos el estimador\n",
    "regresion_sm = reg_sm.fit()\n",
    "regresion_sm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>salary</td>      <th>  R-squared:         </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0978</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:39:49</td>     <th>  Log-Likelihood:    </th> <td> -1804.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   209</td>      <th>  AIC:               </th> <td>   3613.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   207</td>      <th>  BIC:               </th> <td>   3620.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  963.1913</td> <td>  213.240</td> <td>    4.517</td> <td> 0.000</td> <td>  542.790</td> <td> 1383.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roe</th>   <td>   18.5012</td> <td>   11.123</td> <td>    1.663</td> <td> 0.098</td> <td>   -3.428</td> <td>   40.431</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>311.096</td> <th>  Durbin-Watson:     </th> <td>   2.105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>31120.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.915</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>61.158</td>  <th>  Cond. No.          </th> <td>    43.3</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 salary   R-squared:                       0.013\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     2.767\n",
       "Date:                Thu, 15 Apr 2021   Prob (F-statistic):             0.0978\n",
       "Time:                        13:39:49   Log-Likelihood:                -1804.5\n",
       "No. Observations:                 209   AIC:                             3613.\n",
       "Df Residuals:                     207   BIC:                             3620.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        963.1913    213.240      4.517      0.000     542.790    1383.592\n",
       "roe           18.5012     11.123      1.663      0.098      -3.428      40.431\n",
       "==============================================================================\n",
       "Omnibus:                      311.096   Durbin-Watson:                   2.105\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31120.902\n",
       "Skew:                           6.915   Prob(JB):                         0.00\n",
       "Kurtosis:                      61.158   Cond. No.                         43.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos las regresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "archi_g = open(r'regsm.pkl', 'wb')\n",
    "pickle.dump(reg_sm, archi_g)\n",
    "archi_g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "archi_o = open(r'regsm.pkl', 'rb')\n",
    "reg_sm = pickle.load(archi_o)\n",
    "archi_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    963.191336\n",
       "roe       18.501186\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sm.fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "archi_g = open(r'regsmf.pkl', 'wb')\n",
    "pickle.dump(reg_smf, archi_g)\n",
    "archi_g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
